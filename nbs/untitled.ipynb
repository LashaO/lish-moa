{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.60'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('data/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('data/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('data/test_features.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atp-sensitive_potassium_channel_antagonist      1\n",
       "erbb2_inhibitor                                 1\n",
       "diuretic                                        6\n",
       "autotaxin_inhibitor                             6\n",
       "protein_phosphatase_inhibitor                   6\n",
       "                                             ... \n",
       "serotonin_receptor_antagonist                 404\n",
       "dopamine_receptor_antagonist                  424\n",
       "cyclooxygenase_inhibitor                      435\n",
       "proteasome_inhibitor                          726\n",
       "nfkb_inhibitor                                832\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.sum()[1:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trt_cp', 'ctl_vehicle'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['cp_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27796, 772)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = 250\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "print(data.shape)\n",
    "pca = (PCA(n_components=n_comp, random_state=42).fit(data[GENES]))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 7.87 s, total: 19.2 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GENES\n",
    "n_comp = 100\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27796, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = 60\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "print(data.shape)\n",
    "pca = (PCA(n_components=n_comp, random_state=42).fit(data[CELLS]))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 752 ms, sys: 1.4 s, total: 2.15 s\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#CELLS\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>977</th>\n",
       "      <th>978</th>\n",
       "      <th>979</th>\n",
       "      <th>980</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>984</th>\n",
       "      <th>985</th>\n",
       "      <th>986</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450285</td>\n",
       "      <td>-0.176778</td>\n",
       "      <td>-1.262943</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>-0.890670</td>\n",
       "      <td>0.393604</td>\n",
       "      <td>-0.703376</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.082941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.429385</td>\n",
       "      <td>-0.226422</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>0.863835</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.669397</td>\n",
       "      <td>0.447651</td>\n",
       "      <td>1.207365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115802</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>-0.212644</td>\n",
       "      <td>-0.902482</td>\n",
       "      <td>-0.118799</td>\n",
       "      <td>-0.336548</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.572233</td>\n",
       "      <td>-0.261651</td>\n",
       "      <td>-0.638141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590366</td>\n",
       "      <td>0.698760</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.147857</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>-1.433683</td>\n",
       "      <td>1.323147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.287454</td>\n",
       "      <td>-0.110246</td>\n",
       "      <td>-0.105291</td>\n",
       "      <td>-0.396913</td>\n",
       "      <td>0.090983</td>\n",
       "      <td>-0.211590</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>-0.326626</td>\n",
       "      <td>-0.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492270</td>\n",
       "      <td>0.802396</td>\n",
       "      <td>0.332499</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>0.238577</td>\n",
       "      <td>-0.483204</td>\n",
       "      <td>0.585078</td>\n",
       "      <td>0.173586</td>\n",
       "      <td>-0.611718</td>\n",
       "      <td>1.607084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.364079</td>\n",
       "      <td>-0.375444</td>\n",
       "      <td>-1.433534</td>\n",
       "      <td>-0.858483</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>0.101450</td>\n",
       "      <td>0.435098</td>\n",
       "      <td>-0.219500</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>0.555680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511130</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>-0.166686</td>\n",
       "      <td>-0.458886</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>0.081750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129357</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>0.302835</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>-1.737516</td>\n",
       "      <td>-0.531532</td>\n",
       "      <td>-0.351892</td>\n",
       "      <td>0.542268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549881</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>1.124858</td>\n",
       "      <td>2.358549</td>\n",
       "      <td>4.598061</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.448931</td>\n",
       "      <td>3.509945</td>\n",
       "      <td>1.710206</td>\n",
       "      <td>-2.434251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows Ã— 991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose       0       1       2  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...     ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "            3       4       5  ...       977       978       979       980  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ... -0.450285 -0.176778 -1.262943  0.219107   \n",
       "1      0.0604  1.0190  0.5207  ...  0.063234  0.658824  0.429385 -0.226422   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.115802  0.726273 -0.212644 -0.902482   \n",
       "3      0.5288  4.0620 -0.8095  ...  0.590366  0.698760  0.050321 -0.793301   \n",
       "4      0.6919  1.4180 -0.8244  ... -0.000223 -0.287454 -0.110246 -0.105291   \n",
       "...       ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ... -0.492270  0.802396  0.332499 -0.204876   \n",
       "23810  0.9905 -0.7178  0.6621  ... -1.364079 -0.375444 -1.433534 -0.858483   \n",
       "23811 -0.7389  0.5505 -0.0159  ... -0.511130 -0.035609 -0.310135 -0.166686   \n",
       "23812  0.2044  0.8531 -0.0343  ... -1.129357  0.020524 -0.043233 -0.440007   \n",
       "23813  0.7952 -0.3611 -3.6750  ...  3.549881  0.367554  1.124858  2.358549   \n",
       "\n",
       "            981       982       983       984       985       986  \n",
       "0     -0.890670  0.393604 -0.703376 -0.615139  0.174407  0.082941  \n",
       "1      0.271831  0.863835  0.003597  0.669397  0.447651  1.207365  \n",
       "2     -0.118799 -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n",
       "3      0.295411  0.147857  0.056161  0.689218 -1.433683  1.323147  \n",
       "4     -0.396913  0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "23809  0.238577 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n",
       "23810  1.072457  0.101450  0.435098 -0.219500  0.377156  0.555680  \n",
       "23811 -0.458886 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n",
       "23812  0.302835  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n",
       "23813  4.598061  0.405195  0.448931  3.509945  1.710206 -2.434251  \n",
       "\n",
       "[23814 rows x 991 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.0)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose       0       1       2       3       4  \\\n",
       "0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "            5       6  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     -1.0120 -1.0220  ...                                      0   \n",
       "1      0.5207  0.2341  ...                                      0   \n",
       "2      1.2390  0.1715  ...                                      0   \n",
       "3     -0.8095 -1.9590  ...                                      0   \n",
       "4     -0.8244 -0.2800  ...                                      0   \n",
       "...       ...     ...  ...                                    ...   \n",
       "21943  0.4256 -0.1166  ...                                      0   \n",
       "21944  0.7201  0.5773  ...                                      0   \n",
       "21945  0.6621 -0.2252  ...                                      0   \n",
       "21946 -0.0343  0.0323  ...                                      0   \n",
       "21947 -3.6750 -1.2420  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "21943             0                0                  0   \n",
       "21944             0                0                  0   \n",
       "21945             0                0                  0   \n",
       "21946             0                0                  0   \n",
       "21947             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "21943                0          0                           0              0  \n",
       "21944                0          0                           0              0  \n",
       "21945                0          0                           0              0  \n",
       "21946                0          0                           0              0  \n",
       "21947                0          0                           0              0  \n",
       "\n",
       "[21948 rows x 1196 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning\n",
    "\n",
    "# for col in GENES:\n",
    "#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n",
    "#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "\n",
    "# plt.figure(figsize=(16,16))\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# gene_choice = np.random.choice(len(GENES), 16)\n",
    "# for i, col in enumerate(gene_choice):\n",
    "#     plt.subplot(4, 4, i+1)\n",
    "#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n",
    "#     plt.title(GENES[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ = train.copy() [Didn't wanted to actually normalize, so created a copy and normalized that for further calculation]\n",
    "# for col in GENES:\n",
    "    \n",
    "# #     train_[col] = (train[col]-np.mean(train[col])) / (np.std(train[col]))\n",
    "    \n",
    "#     mean = train_[col].mean()\n",
    "#     std = train_[col].std()\n",
    "\n",
    "#     std_r = mean + 4*std\n",
    "#     std_l = mean - 4*std\n",
    "\n",
    "#     drop = train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values\n",
    "\n",
    "# train = train.drop(drop).reset_index(drop=True)\n",
    "# # folds = folds.drop(drop).reset_index(drop=True)\n",
    "# target = target.drop(drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_comp = 50\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train[CELLS]), pd.DataFrame(test[CELLS])])\n",
    "# data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "# train2 = data2[:train.shape[0]]; test2 = data2[train.shape[0]:]\n",
    "\n",
    "# train2 = pd.DataFrame(train2, columns=[f'c-{i}' for i in range(n_comp)])\n",
    "# test2 = pd.DataFrame(test2, columns=[f'c-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "# train = train.drop(columns=drop_cols)\n",
    "# test = test.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose       0       1       2       3       4  \\\n",
       "0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "            5       6  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0     -1.0120 -1.0220  ...             0                0                  0   \n",
       "1      0.5207  0.2341  ...             0                0                  0   \n",
       "2      1.2390  0.1715  ...             0                0                  0   \n",
       "3     -0.8095 -1.9590  ...             0                0                  0   \n",
       "4     -0.8244 -0.2800  ...             0                0                  0   \n",
       "...       ...     ...  ...           ...              ...                ...   \n",
       "21943  0.4256 -0.1166  ...             0                0                  0   \n",
       "21944  0.7201  0.5773  ...             0                0                  0   \n",
       "21945  0.6621 -0.2252  ...             0                0                  0   \n",
       "21946 -0.0343  0.0323  ...             0                0                  0   \n",
       "21947 -3.6750 -1.2420  ...             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                    0          0                           0              0   \n",
       "1                    0          0                           0              0   \n",
       "2                    0          0                           0              0   \n",
       "3                    0          0                           0              0   \n",
       "4                    0          0                           0              0   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943                0          0                           0              0   \n",
       "21944                0          0                           0              0   \n",
       "21945                0          0                           0              0   \n",
       "21946                0          0                           0              0   \n",
       "21947                0          0                           0              0   \n",
       "\n",
       "       kfold  \n",
       "0          0  \n",
       "1          2  \n",
       "2          1  \n",
       "3          2  \n",
       "4          2  \n",
       "...      ...  \n",
       "21943      0  \n",
       "21944      4  \n",
       "21945      0  \n",
       "21946      1  \n",
       "21947      2  \n",
       "\n",
       "[21948 rows x 1197 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1196)\n",
      "(21948, 1197)\n",
      "(3624, 990)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-2\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf419154d3e43d28465294a352f3de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 0\n",
    "fold = 0 \n",
    "\n",
    "seed_everything(seed)\n",
    "\n",
    "train = process_data(folds)\n",
    "test_ = process_data(test)\n",
    "\n",
    "trn_idx = train[train['kfold'] != fold].index\n",
    "val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "\n",
    "class MoADataset_:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return (dct['x'], dct['y'])#dct\n",
    "\n",
    "train_dataset = MoADataset_(x_train, y_train)\n",
    "valid_dataset = MoADataset_(x_valid, y_valid)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = Model(\n",
    "    num_features=num_features,\n",
    "    num_targets=num_targets,\n",
    "    hidden_size=hidden_size,\n",
    ")\n",
    "\n",
    "#model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-7, weight_decay=WEIGHT_DECAY)\n",
    "# scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "#                                           max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(trainloader, end_lr=10, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=LEARNING_RATE, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.6023772686611915\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.07887100130319595\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.028685520241117996\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02093298988682883\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02034540435947154\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.0187058510524886\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.019012042678946604\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017973228144858563\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01827094193035062\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017511060488011154\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.0178603231029558\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017287100558834416\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017578802651901176\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01715779626475913\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01743261217126164\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017031403311661312\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017271661084901163\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017034198982375008\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017240723284582298\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.016992094474179403\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017331369619384623\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01708046312310866\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017374625065080498\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01710237166179078\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017322135110642168\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.0170431861653924\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017283108719773052\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.016962244042328427\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01736558319163927\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01702551024832896\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017230181563375652\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016988845036498137\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01722372474445813\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016903411783277988\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01715227122000162\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016805297242743628\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017019336766468874\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01674529111811093\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016920703186559072\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016686984710395335\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016873915079117254\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016589991828160625\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016736862202431414\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01648565823478358\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016552735707196203\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016461943223008087\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01634705852906125\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016298214106687477\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.01608230261321085\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016248903024409497\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015868619651250217\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01611781750938722\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015594334726262352\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01601789891719818\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.01541182678192854\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01598800966250045\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01525525557741091\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.015971971063741614\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015248677234394827\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.01595560099397387\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5979133640834386\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.06961478484528405\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02790458219638769\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02032999720956598\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020513987087685127\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01886744052171707\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018913759492283713\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01792806921792882\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018138488828865946\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01742664466478995\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017739496112841625\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017149395043296472\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017529629677048197\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017138852844280857\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01740773840793881\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017157525542591298\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017486270044700825\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017083268080438887\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017453873428799536\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017178881328020777\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017450557502013617\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01716451139322349\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.0174382993263071\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01712024113429444\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01743674800609765\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017092246881553103\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017375127500112074\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017000287105994567\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017434486349963623\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017064795403608255\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017342151540830946\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016993220895528793\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017233080068684143\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016882227467639104\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.017201771284791008\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016942819101469858\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017127718499767176\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016891466240797723\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.017047071498751207\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016870100636567388\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01683865345177659\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016743300589067596\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.016703844414619\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016558389684983663\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01655234856719988\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016433643363416194\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016361265328537294\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01636978576758078\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016092338788228622\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016289617946105343\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01587967695398391\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.01617467028221914\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.01562607853902855\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016122939357800143\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015436852789497461\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01607731067176376\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015279504538014315\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.016034004837274553\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015230790624206049\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016029021303568567\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5985332562763622\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.06755820693714278\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.028319833719212074\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020558939714516913\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020338039048879906\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019404313606875282\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018997760692044445\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01784671260310071\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018115953083379543\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017375847111855233\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.0176735015693998\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01731516114835228\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01754053026113821\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017155937823866096\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.01745246660531215\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01725731095565217\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01734732554388651\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017181152291595937\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017449544209555006\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017174919162477764\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017462653803058725\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017086714639195373\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017445987522386124\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017179100295262678\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01751591797000256\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017246139076139245\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017458619840065207\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017079846188426017\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017314224409452385\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01702831078852926\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017300052062162886\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017092655492680412\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017336601911085672\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016959001310169697\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017300992522496676\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016925233735569884\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01711308966944183\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01684371307492256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 19, train_loss: 0.01704892175326097\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016701590589114596\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01690364855112157\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01661411909652608\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01671208618748663\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01654167417436838\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01663734349489644\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016412964330187865\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016403867795631504\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016365275558616433\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.01619093082980185\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01617913054568427\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.01593863424858537\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.0161050733178854\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01569780171511398\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.016026914625295572\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.01556998631660489\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01597363565649305\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015428814922283957\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01596023560102497\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.01534494148918252\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015954748993473395\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6009301446054293\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.06825575998851231\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.027192166642002438\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02075582572392055\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020320205807523882\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01874983571469784\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018786554170799427\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017994863859244755\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.01792148287421551\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017448582872748374\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017566684120591137\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01729191637464932\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.01739960962879485\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017329059727489948\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01743371233317083\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.0172612250117319\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017351077700816633\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017142396845987864\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017460449517745037\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017386993579566478\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017436177240333695\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01736417654901743\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017467863716023123\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017227905137198313\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017431677548565727\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01730957217514515\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.01738096995657121\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017188577593437265\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017370898175336744\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01728241659168686\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017336518962638103\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01723671696547951\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01726547663734443\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01712009326687881\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017140610305511433\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017082638080630985\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017078368236189304\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01696121607507978\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01696917342453979\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016940045755888734\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01679913144207735\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01682378194694008\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016713502796609766\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01673462279140949\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016502030780943838\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01673464027366468\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016319161247246076\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016536861099302767\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016119569742485233\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016397514886089735\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015873243073946323\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016311259434691496\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015604361473326233\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01627261649285044\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015398887148045975\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016231905589146275\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015323956031352282\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016241269053093026\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015237344138702189\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01620278773563249\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6010857083011365\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.07653656708342689\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.028757465895319332\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02140039423746722\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020583813294660355\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01908995264342853\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.019138104828965406\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.018047846614250115\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018317566867377878\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01766408570110798\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017864923377561827\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017362312972545625\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01762920658549537\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017350830723132406\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017512960366202868\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017281397911054746\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.01746228664600547\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017100886840905462\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017363838318303442\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017081954463252\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017348565923832895\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017098032044512886\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017401430411669222\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01700289265385696\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01735392314773323\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017354053817689417\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017392486509313618\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01704102735966444\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017410824885186943\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017076502394463334\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017327811609467735\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017010415638131753\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017292850887051958\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016891555727592537\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.017115220387020836\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01687582909528698\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01710526672853292\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016944918036460876\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01698844154378858\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016643406530576093\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016776366925298953\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016563766742391246\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01663371064848658\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016426241318030017\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01650068960894925\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01640028663511787\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016322510101009106\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016280280505972248\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016031601817171642\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01619207773889814\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015808266459329836\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.01604370932493891\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015554970548744652\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.016015570424497128\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015412697622525518\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015912139176258017\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015270268767262283\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01591220601860966\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015193283213707416\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015925396952245915\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5985224828447985\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.06500865263598306\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.028167331361792225\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02038247947181974\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020225130197038685\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01872448692364352\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.018875923642105816\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017972228010850293\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01823984200566791\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01743715876447303\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017723907959526\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01721456034907273\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01742773626566581\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01716352001364742\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.0173714980415568\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017263175201203143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 8, train_loss: 0.01745394225218806\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01711817170892443\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.0173775945601148\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01710172723978758\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01742125880917993\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017086966309164252\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017427959695350433\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017046836311263698\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017374445974448885\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017140789196959563\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017400466621030067\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017054808113191808\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01741034580745559\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017110936556543624\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017344892794347328\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016978072641151292\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.017245004048058087\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.0170388611299651\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017209932127076645\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016789296961256434\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017064399106185072\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01681349336036614\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016994730252232672\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016798623305346285\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016891098972679913\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01666228904255799\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016683354231434456\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016648125728326184\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016607806761411652\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01650199451084648\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016382666709630386\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016398477713976588\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016100070122089506\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016221583581396512\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015842131527977577\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016149815624313696\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.01559388652389896\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01604208227779184\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015457718437402576\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01599992263529982\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015307058067317459\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.015970745656107153\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.01525664950410525\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.015967246384492942\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5994936936683413\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.0655422140445028\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.027566970393493557\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020033438716615948\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020463719734571117\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018677830030875548\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018962840326940237\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01820163955645902\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018092250363712294\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017471371803964887\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017643481337775786\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017370582771088397\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.01755261079718669\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01711508956338678\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017453995000139094\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017195132481200356\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.0174033979723311\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01713203801108258\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017459055361594412\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017229839095047543\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01753946499683071\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017123446294239588\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017430839675438146\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017096654857907977\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01743279381290726\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017161277468715395\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017331628904988367\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017233756503888538\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.0173767084741722\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017007915249892643\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017337894283127094\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01702233414564814\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017261759695205568\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.017020860420806066\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.017193927078683308\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016939225287309716\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017093529189140467\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01685738880187273\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016967787852753765\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016719364215220724\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016795744113894045\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016683009000761168\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.016719867785771687\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016635623494429246\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01653582730964906\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01656963066863162\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01633969018154818\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016262834572366307\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016070917457936033\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016248842382005284\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.015883586065762716\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.01622355284967593\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015661600909695244\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01612466861094747\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015414457639976255\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016078970820776053\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015314046732163515\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01604127495416573\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015232414763042892\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01609630531498364\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6023393904493339\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.0685168640954154\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.027738168322737667\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02034095355442592\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020100444575528734\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01863757244178227\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018983029267764177\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018356894382408687\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01851110843995559\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017644721056733814\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017798753259568544\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01730380007731063\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017584826702764934\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017216920293867587\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017435252092832674\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01712894442358187\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017374314691709435\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017036374738173824\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017427240943779117\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01710511882390295\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017403707684328158\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01741684214877231\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017500459985888523\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017098607921174593\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017429130307088297\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017183825985661576\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017446149903201105\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01729512826672622\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017469491593647694\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017107128777674268\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017377319934683434\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01711492996130671\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017309506646478953\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016857676660375936\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017209753083686035\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016860448249748774\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017087127311506134\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016744748077222277\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.0169932152401062\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016709356621972152\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016897437088461458\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01664012029234852\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.0167679401398029\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016514120330767972\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016541804902363514\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016363753431609698\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016327246341962313\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016190565058163235\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.01610228599494566\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01616608082715954\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015791494075370872\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016031387554747718\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.015682998889436323\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01603012460150889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 27, train_loss: 0.015421291981972214\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01595220799957003\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015342713927553184\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015963621836687838\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015205533594648907\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015903956496289798\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6010481828580732\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.06692949682474136\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.027991757566190285\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02048976868391037\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020414837588812563\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01884287531886782\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018821341633472755\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018129034579864572\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018141687739694465\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017787205640758787\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01766464969251251\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017376748472452165\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017443490147158718\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017338062556726593\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01737302217794501\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01727550748203482\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01741370510822837\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01756371089390346\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017407735708453085\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01732564845255443\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017398708081547764\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017260988296142647\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017447647780341947\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017379216317619597\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017444590322565342\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017556055981133665\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017402339827917192\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017461081594228746\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017381261683244636\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017256270349025726\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017338741523470137\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01723960622080735\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01724930918114125\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017166510783135892\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017181561625414135\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.0169518752555762\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017078899940394836\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01695873165237052\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016993565869558115\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01701322378856795\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016840340056713077\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016809491094733987\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016763015508489763\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01673622280359268\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016535414106118074\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016613620892167093\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016369860443839993\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016530747578612396\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016119670723497435\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01644190903753042\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015873253068792215\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016315651232642787\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.01563973597291371\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016206808973635946\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015486796649739794\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016177032169486794\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.01533965490407486\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01617604632462774\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.01525427975381414\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.01614474624927555\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.600757600982552\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.07514380450759615\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.028085964259462082\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02048217350883143\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.0205807626058442\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01896714914057936\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01896312583129907\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017848114483058453\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018016146630912586\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017471910933298723\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017704953230323568\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017264387596930775\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01742179827440692\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017068935265498502\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017473805628285027\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017117224128118582\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017482131483384233\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.0171117065474391\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01747570392689195\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017269813987825598\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017524404444502317\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01716613836054291\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.01752309092199025\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017253729541386875\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017520182610799868\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017038146113710743\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017347594432910715\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.016994423578892436\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017413439843263746\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017051403517169612\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017347004264593124\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01702534971492631\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017407366148857534\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016988591823194708\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.017239105651506048\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01692000515758991\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017189133925822334\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016832613732133593\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01698188804278987\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01667301066751991\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016910801068002333\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01664430041398321\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01681796796079995\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016575284781200544\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016558271151144003\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016353101522794792\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01641988240695302\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016248196017529283\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016141983315996502\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01617380665349109\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015941931778376085\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.01607724345688309\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015686301001604053\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.016008083735193523\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015522380973603846\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01593722610601357\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015371951949445234\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015934276900121145\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.01532516320762427\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015916447634143488\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5970990951510443\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.068105448782444\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.028306845427099346\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.0208544738058533\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.0204375965817683\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018454469314643316\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01903871824775917\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017773011858974185\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018108583278144182\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017421843191342695\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017742667455172192\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017191492287175997\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017486217829898214\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017042183982474462\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01747208365333685\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.0172871664964727\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017401966705000486\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017222852605794158\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017407665758029274\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017294955759176184\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01747315292638065\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01716702612383025\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017437270613036293\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.0170826418325305\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017486974151562088\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01722311201904501\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017367392083279032\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017142018276665894\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017377769830974117\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017050279464040485\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017379215365086777\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017047089631003993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 16, train_loss: 0.01727376056943035\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01693334731140307\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017261287858844666\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016915321057396276\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017188234477425398\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016830918618610927\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01695409898335735\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01674631331115961\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016825329782306286\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016641351075044702\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.0166667473529452\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016517986011292254\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01658221411154322\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016437809967568943\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01633326471040862\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01640172853533711\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016153577188758747\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01623031249535935\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015889088110323402\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.0161530056436147\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015693447255677936\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016028268794928278\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015483558454645285\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.016006692525531566\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015381917161732048\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.015981830124344145\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015254673615529917\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.016033424676529\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6002621743018213\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.06797651350498199\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028544962041727875\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02062308176287583\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02045565584431524\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018923577080879894\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.019121125003026016\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.018463778815099172\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018308436005389776\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01757379626589162\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017620806987194912\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017277165981275693\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.01743251368727373\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017421212872224194\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01727111008612142\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017048800949539457\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01741865549263531\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01703545773135764\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01736186815938656\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01721271039651973\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017428918363715427\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017060972537313188\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017418927330847666\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01711873643632446\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017371177457380985\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01708064241600888\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.01734894389907519\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017000161563711508\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017284725077342297\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016940271402043957\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017328769677197157\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01720662715711764\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01720287162216677\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016888892943305627\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01718301303765696\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016838866285979748\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01714838910308005\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01676712137247835\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016989658377470747\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016760648201618877\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016816813431248284\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01662083340010473\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.016685120005538498\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016565922860588347\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01653204786091827\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01638376031603132\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016270197334064953\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016313908728105682\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016078631805283003\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016319514491728374\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.015846310034934162\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016176678399954524\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015582726154800343\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016135495954326222\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015424329342077608\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016067769644515856\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01533630133970924\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.016036820757601943\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015194112461978111\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01608302699668067\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5969243220768977\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.06348764672875404\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02789554084934618\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020557721012404988\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020374164707364813\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018788218551448414\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.0190183957701252\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01786757611802646\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018428568100637716\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01738871977265392\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01772500990309577\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01721042368028845\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01749484029099129\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017088674620858262\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017467970116252916\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017063084856740067\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.0173901181222628\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017344495707324572\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01739105261673314\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01704236503158297\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017466684945089662\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017209113309425966\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017400046000662056\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017203918445323194\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01740799153196639\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017241405057055608\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017346313547181046\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017098137869366578\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017316761568350637\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01701417895300048\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01733625316452505\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017086405067571572\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017307195049859045\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016910265093403203\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017255896769895935\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016884418869657174\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01709176523718929\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016740063897200994\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.017068898534753185\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01668803399162633\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01685617050236982\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01658505547259535\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01666735451452542\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016512667946517467\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016583979042057974\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016458060858505114\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016282972015872383\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016287624995623317\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016080029470765072\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016134883729474886\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.01588298096254036\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016069123707711696\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01566002189276227\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.016002356819808484\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015439426688396412\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01593755840190819\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015285704419880674\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015932260267436504\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015242440254845913\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015939389036170076\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6000062056641647\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.07320357135363988\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.028280894973895687\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020956257304974964\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020094292946969686\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.019172414179359165\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.01881885877472983\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018253055081835817\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018064686016220112\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017699823209217615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 5, train_loss: 0.01767557934331505\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01755376798766\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.01745410967429263\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017354362245116915\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017373342390941536\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017220675652580602\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017353284375175186\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017711630037852696\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017463069206670574\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017353383771010807\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.0173551178658786\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01738839750843389\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017374575286563755\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01735339891165495\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01744099741504676\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017287534634981838\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017414937983604446\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01742645448872021\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017344272938435493\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017171891565833774\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017292844489270796\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01717666621719088\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017261663431544668\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017242728705917088\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017141138864816097\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017084222553031787\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017135735918376326\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017008837738207407\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01696127613304534\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016899002875600543\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016907970528995644\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016813086319182602\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016705863096791763\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01670137071715934\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016498936475187107\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016678695593561443\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016300031429399616\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016508034989237787\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016097568036259516\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01638992838561535\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015865749605269968\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.01633511326674904\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015667432534467916\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016240216525537626\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015398938100839006\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016219399816223553\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015326604658764774\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01621468487594809\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015251013679780823\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016186859432075706\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5997463432883007\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06517134074653898\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02835293710771678\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.021332731364028794\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.0205256555877302\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.019060076347419193\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.018989686496501814\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017913874185511044\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01815049029022887\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01754301158445222\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017760223202893267\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017204554485423223\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017601667201497417\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017071137337812355\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017446741623722988\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01708592250943184\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017419858329483996\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01722289068358285\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017388575541638376\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01713511526052441\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017445689985069675\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017198531622333185\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017520076548005793\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017086878498750072\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017463376779325197\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01703497285821608\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017446802618602913\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017091165349951812\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017376898841905422\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01709290455494608\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017393848818281422\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017198130461786476\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017339615144537412\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01694985247616257\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01718580905024124\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016984017858547824\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017134811924905447\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01678551219935928\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01699816662332286\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01673495817397322\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01686623076354896\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016503499395080976\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01669904127366085\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01648328753986529\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016463251845182283\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01638218608817884\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01631361449920181\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016257177532783575\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01611249999858547\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.0161945551899927\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015936796587176512\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016043456963130406\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.0156697492601107\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.015995464234479836\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015482432296688574\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015935426764190196\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015339897783554119\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015898711287549563\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015321339149891899\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015912333636411598\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6018165604251883\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.07266145603997366\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.028129300777462944\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02047443219593593\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020388847621886627\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018550016039184162\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.019031478611725397\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017837263803396907\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01811930929324117\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017440230106668814\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017683619856024565\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017257014555590495\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01754476959425686\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017284338495561054\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01746115680999946\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017588665203324385\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01742834326527689\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01715150786829846\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.01737724687985104\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017093365426574435\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017468553927281628\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017162035911210946\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017457151529041752\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017096095558788094\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01750942470802777\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01715617280985628\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017470814787067364\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017197069419281823\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017403560177679512\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017073714520250048\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017391275297310473\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017037525134427207\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01734001078116505\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016945090544010912\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017151143962004477\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01695500732000385\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017147423551026462\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016798459126480987\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016987089486117813\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01672474800476006\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01683985058596169\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016636548271136625\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016792663049114788\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016582757367619445\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016568131042995315\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016473175744925225\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01644174675659641\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016312915299619948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 24, train_loss: 0.016152160296189613\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016302668090377535\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015895041184958773\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01615759932569095\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015688634119873892\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01605684765215431\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015507146898333145\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.016016444989613125\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015330846691369146\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01600418955619846\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015347965770279583\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.015976383962801526\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.601437650890886\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.0669287981731551\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028180945799618527\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02070949710905552\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020392653653803078\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01890005549149854\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.019190473866689463\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.018148563163621085\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018263860720385244\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017567092765654838\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017740270095890846\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017262092498796327\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017448739324142967\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01715028304606676\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017319938458124365\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017219837701746395\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017414109781384468\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01727907636335918\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017370131582129692\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017072143565331186\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01741077571405449\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017278841058058398\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017460998107233772\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017166085860558917\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017357885142437357\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01725547468023641\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017390783795196076\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017004545458725522\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017425840200883322\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017204065221760954\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01727823968436839\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01693564576229879\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01724353439404049\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01709185412951878\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.017152887593576874\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01686644862805094\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017091948059859915\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01682714242488146\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01688965334408525\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016772278212010862\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016802588558715324\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01671668937695878\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.016712017175134108\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016579304129949637\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01650103053374999\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.0165031976465668\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016225554143497044\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016323845141700336\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016081392245394163\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01627028983618532\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01580093468984832\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016190959326922893\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015549626194642506\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01614280678331852\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015396218908869701\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01605780848434993\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015228117917380903\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01606059210108859\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.01519021209653305\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016082006080874376\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6023672105393548\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.07324027014630181\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02803100231171086\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02046625486442021\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020680059300924557\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018976801899927002\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018910260344653027\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01796404785875763\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01827356695750917\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017525431008211204\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017746961506866457\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.0172243186671819\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017507102745382683\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017032065907759325\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017339249276488587\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01707240289875439\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017312401311769\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.016973141048635756\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017361326892252848\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017150730373603956\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017430186150190624\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01717823131808213\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017451746200305828\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01718422698655299\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01741315487880206\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017180800092007432\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.01745930106203625\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01700324501310076\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01736108995164218\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01710682913128819\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017326295591782833\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017056658917239734\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01724624661458791\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01710648504751069\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01725274458716529\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01683625640081508\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01709945994577762\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01683809086680412\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.0169691596099216\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016797613432364803\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016841505100761635\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01658133345523051\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016732025263912004\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01648506751017911\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016520004085116627\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01644504935081516\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016359361388005207\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016213265779827322\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016127055119453133\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016193696643624987\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.01587852552884083\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.01601499566542251\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.0156624310352988\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.015963422640093736\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015422018764513558\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01590958493096488\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015309940638911465\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.0158847772117172\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015258249550032011\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015877612440713815\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6007054191676603\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.06547609865665435\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.028005206323080303\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020462883370263234\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020190929805023083\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018710416555404664\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018994256746077885\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018092845300478593\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.01798506847758224\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017833162524870463\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017658260846645502\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01743318047374487\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.01750090245184475\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017313166760972568\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.0173751941099223\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017366150287645203\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017420162588519895\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017286866158246993\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017427540519207283\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017373679924224103\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017300463463787153\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017385905927845408\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017470964007889448\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01728584463042872\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017391223892353584\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017211818668459142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 13, train_loss: 0.01738417618975475\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.0174440896404641\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01744739209855164\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01719922689454896\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01730281772577892\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017136748880147934\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017235011415745037\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017110639225159374\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017202979223667713\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01699865340654339\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017128941791968933\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016966181195208003\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.0169319040276974\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01699853225478104\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01681208711090511\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016789827256330422\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016724600341926882\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01680223981716803\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016498186247612255\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016632650127368313\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016369471016029518\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.0164742467126676\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016077611703371655\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01639993307845933\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015797746455485838\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016284375158803804\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015567399601897468\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01624057042811598\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015326143377393053\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016178512812725136\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015247566247547882\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01620029006153345\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.01519500840779232\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016144649711038385\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6008659033239752\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06683840709073204\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.027592259229741234\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020801891226853643\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02041496568615886\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018869602999516896\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.018989201257194298\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01803191817764725\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01817696548971361\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01740572274263416\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017644010727172314\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01725205739161798\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01752049342283736\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017170162153031146\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017421075811042734\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017379760476095334\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017480076101703056\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017102742328175477\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017490555653753487\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01726633757352829\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017491241107168404\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017241405669067587\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017452700002847807\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01714854666164943\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01745442967807901\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017111828231385778\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.0175858977979616\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01706209108233452\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017427472539408052\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017109272682241033\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01739250972489084\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017242901905306748\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01732311972781368\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016961662790605\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01722605614180582\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016901719543550697\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017090300637958706\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01686050415571247\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01698706531222316\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016723258021686758\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016848316740082657\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016668165448520865\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016772349742983562\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01652727709817035\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016582394801620125\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.0164086270279118\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016396122687644718\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01638477428683213\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016158846179968205\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016219510031597956\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015941503903140194\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016155911423265935\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015713721412517454\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.016055477197681155\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.01550038337059643\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01602118904037135\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015380461841983639\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015964301223201412\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.0152952011026766\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01597910494144474\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6011705389921216\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.06367419000182833\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027586530462123345\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020269413079534258\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020300650361763393\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018514482091580117\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.018848454680941675\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.0177829381610666\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018069549726889185\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017428007615464074\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017759520965425865\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017320829709725722\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.0175404894111705\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01702467751290117\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01736177255709966\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017118046006986073\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017432909938034372\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.0171987775181021\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017525762387051964\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017260370829275676\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017419610408715147\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017159670990492617\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017428738017822954\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01700083626700299\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.0173753769190955\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01700473664594548\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017469951761481556\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017082414563213077\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.01737619035512857\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017075042054057122\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01729736723464684\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016966445052198003\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01722024999342967\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.017060893082192965\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017255264624575342\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016943507162587985\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017180661758596914\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016830746031233242\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.017027926509794983\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01675074872161661\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016752233276602583\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016620575849499022\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016635792674091848\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.01647865426327501\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016501541789351166\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01644809325890882\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01627392104516427\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016332120395132474\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016130377329292074\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016246963984199933\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015884377312023138\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01615586331380265\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015669751041771277\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016131697462073394\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015507860615363588\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.015991636418870518\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015272300494699806\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01602443414075034\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015231083633135195\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.01599785653608186\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5994898605605831\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.06618458990539823\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02794833296397026\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020865151126469885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 2, train_loss: 0.02035139403913332\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01900206229516438\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018918649185502876\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017835500330797265\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.01809436329168038\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017448432557284833\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.01760381160546904\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017179548048547336\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.01741018424998375\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017278109224779264\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017387651453685503\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017127661460212298\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017428845673313608\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017255885978894575\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017425432274846928\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017072400264441966\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017403781279057697\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017141569139701978\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017439312639011852\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017231303027697972\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01738349805869486\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017220885146941457\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.0173670698861605\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017101744934916497\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017309478639314573\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017247558837490424\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01738511193273724\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017215220869651864\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017274253455031176\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01700015618864979\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01716361763090759\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016886167707187788\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017142720560988655\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016831173561513424\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.017041262063751186\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016779680603316853\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016925066318093002\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016744474773960454\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01671324091275101\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016649420798889227\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016553005608527557\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016478891378002507\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016300931093755407\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.0163917301222682\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016112349886933098\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016245340875216892\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01589160170271129\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016177859450025218\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.01570404686735592\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016118882223963737\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015491533896251432\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.0160528799785035\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015350800034576569\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01605267261287996\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015251309367949549\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016025173956794397\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.59999287409195\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.07067369222640991\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02803943225223085\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020457708835601808\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02033000788313971\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01881878599524498\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018937226722313873\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01794928674186979\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018074274447787066\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.0173262660790767\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017693116498328207\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017185480387083122\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017502787435238344\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01704749342586313\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017438243797885767\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017078408572290624\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01743687998395467\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017150859108992986\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01747423536616607\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017232913763395377\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017421076317196308\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017106067655341967\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017476318599791197\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017056738372359957\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017445807392452505\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01725058627447912\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017516774921745495\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01712078782064574\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017421274553930412\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017281509217407023\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017407031628586676\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017042997506048\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01734419895902924\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01689238715916872\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017189359683813393\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01695311710770641\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01715886805449491\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01696812119334936\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.017025515747567017\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016694608410554274\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01680920810263226\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016617902927100657\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016710389304258253\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016473506417657647\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016551791332608114\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016441641827779158\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016341879646685244\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01626670147691454\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.0161277054593075\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016164904007954256\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015927379181527573\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016043637320399283\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01567388352924499\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01601395503218685\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015527543571332226\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01593270410916635\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015393530565273502\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01593372720692839\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015283289385716553\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015951845635260854\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5998138856628666\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.09474176232303892\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02854145331767158\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020445040560194423\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020480338160110557\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018981811084917612\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.01908736852794022\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01800092040960278\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018122732808030603\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017836697133524076\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.0177258917575945\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01744041932480676\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017500044244840956\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.01731248793325254\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01743328782554338\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017328167147934437\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017348950107892353\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017287508584558964\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017355324862443882\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017319947481155396\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017405820956480675\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017283545727176327\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017400099929638098\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01726370235638959\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01741583610250466\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017359422839113643\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017331583465894928\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017201759134020125\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017339700313311987\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.0171049192281706\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017247717746573944\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017010078712233475\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01720146129609666\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017161021009087563\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01713058554256956\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01712120808660984\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017112548078369837\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016995331751448767\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01694280810762143\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016879459843039513\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016807761448233025\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016753332183829375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 21, train_loss: 0.016633680549220764\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016678615952176706\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01645653037543314\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016528914256819658\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016275558047050585\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016472585153366838\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016047456686425467\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016288535296916963\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.01582006350213635\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016281531085925442\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015551706404843624\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016219028058860982\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015356152784079313\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016148112288543157\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.0151942179173879\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01610445941665343\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015145501749509054\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.0161380567454866\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6004057493654714\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06860063139881406\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.028034480491086193\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.021205446869134902\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02037234438340301\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01870234502213342\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.018894662284224793\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017822817686413014\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01826152820949969\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017638430797627995\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017794916649227558\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017258956868733678\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017534657098028972\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017162822373211383\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01733408699594978\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017119041244898523\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017462216979027657\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017211219694997584\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01741241889776311\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017038815867687976\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017462893314929544\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017136254800217493\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017411713461405125\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017199801414140632\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01742332106780099\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017102813108691148\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017465574329422005\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01720836487199579\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017418086589516504\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017111441147114548\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017324802168793438\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01728001864893096\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017333000486689634\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01695299076714686\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01722725283732449\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016917549153523784\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01708049967588074\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016796687005886008\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016979380274542433\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.0166618767327496\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016917785217958517\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01666921568768365\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016704256707073553\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016457227511065348\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016533606881410746\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016363459958561827\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01633466873317957\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016291951414729867\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01616774071547864\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01619528750223773\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015903662039857845\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016091626988989968\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015682651175428993\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01602677460759878\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015464491413339325\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015981237909623556\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015362529974916706\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015949209806110178\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.01524442698860514\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.0159606058416622\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5975383494751177\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.0746247125523431\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.02829535212367773\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02123114104781832\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02069637315698724\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01890259443649224\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01920586833865314\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.01798714159854821\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01840479486365465\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017482970521918367\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017862936535823173\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017328099720180033\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017619955792105284\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017216833867132665\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017446855542020523\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01715477162173816\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01738867001014127\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.01702794209122658\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017347429588815008\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017144536865609034\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.01732273181171521\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017093315880213466\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01735696431411349\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017150028741785457\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017388207514000976\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017295448003070694\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017350632548872112\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017029782570898534\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017332813824000565\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017192210789237702\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017220604604623026\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01715252942272595\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.017189712553838457\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016899688568498408\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017086460747742567\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016781084558793475\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017068886657016002\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01677559624825205\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016961006204719128\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01661194395273924\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016795117657739615\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016637115100664752\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01664573971883974\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016489460026579243\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016461505844811167\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01643650694085019\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016249411820393543\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01630124154367617\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.015985180313388508\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016190399282744954\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015754025098800226\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016085232102445193\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.01556946191450824\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016031084608818802\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015310907594697632\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01600830177111285\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015166254241721354\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01597746999136039\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015129477399792791\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.01595130166304963\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5983101819520411\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.0774463992033686\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028308424855703892\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020129984085048947\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020753955360555996\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019083350311432566\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.01890400810626106\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017887912770467144\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018223028630018234\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01741811502724886\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017715306082011564\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01714137622288295\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017534555334165907\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017305089187409195\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017405287376132565\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.0171728289020913\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017361971617176914\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017205895270620074\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.01735878343005543\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01704216692596674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 10, train_loss: 0.017335286991589743\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01718955582806042\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01736271792374875\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01708263853298766\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017303885750310576\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017126782531184808\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017422077441723017\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017073452259813035\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01735696958485937\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01704975116465773\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017277330821514992\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.0170797074213624\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017209941474045965\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01694246804607766\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01717113469308917\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016901622393301556\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01710559832661048\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016798406999026027\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.017001611916213365\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016634406096168928\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01680226711070408\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016613125960741725\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01660150213275051\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01653731968253851\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01641579832125833\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016430585166173323\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016214419594979372\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01631504095026425\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016006532678569572\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01622155832925013\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01577825300341499\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016136110653834683\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015551095119798962\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.01610908918082714\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015332124837120806\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.01605797614902258\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015241816039264633\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01602867655456066\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015149735481194828\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016040564195386003\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5982114740687868\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.07342574979577746\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02788311585891938\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020949823994721686\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020497417225893856\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019013393989631106\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018912908938321947\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017849322807575976\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018314387710036142\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01762194401983704\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01768005326849179\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017141064549131054\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.01747803052590377\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017054378507392748\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017454039312197245\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017063581065407823\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017391817509264187\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017155859805643558\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017457219596574272\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017169956836317266\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017525071136491453\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017280608974397184\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017508813996623823\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.0170936219394207\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017392656678144915\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017087258664625033\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017416048133610817\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017084558787090438\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017395639542382265\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.016967901028692722\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01741254790618584\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016956231822924956\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017295544690358034\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017013301327824592\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01731257405186045\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016880999079772405\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017131214300035568\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.01682224760630301\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01713303688481666\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016709822629179274\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016862783425798018\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016606054694524832\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016791045726479395\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01650996942605291\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01650888235240743\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01646262127906084\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016407387776543266\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01631846973406417\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016151715393947517\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016181636388812745\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015952596440911293\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016058901830443315\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01573172702278564\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.016010474573288646\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015523399381587902\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.015955945583326477\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015425459353550188\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015927661689264433\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015344201404925274\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015930775366723538\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5993475185680217\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0712959178856441\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.028139086831631004\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02073775865137577\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020346223822106487\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018691104810152737\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.01886645537139713\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018006801658443043\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018112460542740166\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01763342334223645\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01768200443652661\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017460245160119875\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017419570044654865\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017283509086285318\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01739833486414906\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01738771503525121\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017449646344597357\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017201948698077882\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017353944527660158\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017218261611248765\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01743882391736775\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01727671953184264\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01742851538448662\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017259277988757406\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017541275271956903\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01719464287161827\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.01740818349239619\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017254576033779553\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017411185880664034\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01709174851753882\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017263901784368183\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01710448813225542\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01722723719380472\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017186541110277176\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017181628815613796\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017094692321760314\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01710301762500751\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017011666058429648\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.017007788029107927\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01683492109711681\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016795052026492962\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016832058876752855\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016699067742118368\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016807634489876884\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016566858991332676\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016620651685765812\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016371136396259502\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016472552823168892\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016051585840034313\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016419270421777453\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015834752922418757\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016284147623394217\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015570187826465437\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016235615499317645\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.01542896569531033\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016190163578305924\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015248686358656572\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016219777933188847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 29, train_loss: 0.015184294229940228\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016197024711540768\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5993579324820767\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06809193598372595\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.028034495392247387\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020454562774726324\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020335610874969025\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018687880198870386\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.019020443525759205\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.019345996103116443\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01819873121364609\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017584028600582054\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01773794990815762\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017923104017972945\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017624237696113793\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017246107411171708\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01745684956456872\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.01734115502664021\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017463352382722973\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017265443397419793\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017531758599469194\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017257387803069183\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017450589936334585\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017191031388938426\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017495917446533407\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.0172102705974664\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017465205478441458\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01703419903559344\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.0174154795071893\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017177441317055907\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01746695048675157\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01700791423874242\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017406938908000786\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017018910311162472\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017304751941043396\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016880355243171965\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.017213060601573925\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01689018415553229\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017150165121732414\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016784109068768364\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.017071688999894304\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016801174942936217\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016834718283211838\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016613459826580117\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016743354870519346\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016552147003156797\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016568302190390186\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016403103912515298\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016430568942071302\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01640584266611508\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01620032082217327\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016180445014366083\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.016021169728828943\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016129449914608684\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015735460560012987\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.016024894639849664\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015547291092250658\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015956992097198964\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015415890533747017\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01596335494624717\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015316844654633947\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015974194849176067\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0, 1, 2, 3 ,4, 5]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014653754863567866\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
