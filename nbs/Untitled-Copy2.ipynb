{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('data/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('data/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('data/test_features.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atp-sensitive_potassium_channel_antagonist      1\n",
       "erbb2_inhibitor                                 1\n",
       "diuretic                                        6\n",
       "autotaxin_inhibitor                             6\n",
       "protein_phosphatase_inhibitor                   6\n",
       "                                             ... \n",
       "serotonin_receptor_antagonist                 404\n",
       "dopamine_receptor_antagonist                  424\n",
       "cyclooxygenase_inhibitor                      435\n",
       "proteasome_inhibitor                          726\n",
       "nfkb_inhibitor                                832\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.sum()[1:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trt_cp', 'ctl_vehicle'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['cp_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27796, 772)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = 250\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "print(data.shape)\n",
    "pca = (PCA(n_components=n_comp, random_state=42).fit(data[GENES]))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 6.06 s, total: 16.1 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GENES\n",
    "n_comp = 100\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27796, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = 60\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "print(data.shape)\n",
    "pca = (PCA(n_components=n_comp, random_state=42).fit(data[CELLS]))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 724 ms, sys: 1.27 s, total: 1.99 s\n",
      "Wall time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#CELLS\n",
    "n_comp = 15\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b2f632b70>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features['g-3'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', 'cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3',\n",
       "       'g-4', 'g-5',\n",
       "       ...\n",
       "       'pca_C-5', 'pca_C-6', 'pca_C-7', 'pca_C-8', 'pca_C-9', 'pca_C-10',\n",
       "       'pca_C-11', 'pca_C-12', 'pca_C-13', 'pca_C-14'],\n",
       "      dtype='object', length=991)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>g-9</th>\n",
       "      <th>...</th>\n",
       "      <th>g-762</th>\n",
       "      <th>g-763</th>\n",
       "      <th>g-764</th>\n",
       "      <th>g-765</th>\n",
       "      <th>g-766</th>\n",
       "      <th>g-767</th>\n",
       "      <th>g-768</th>\n",
       "      <th>g-769</th>\n",
       "      <th>g-770</th>\n",
       "      <th>g-771</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.248366</td>\n",
       "      <td>-0.095684</td>\n",
       "      <td>0.152253</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>0.057347</td>\n",
       "      <td>-0.138836</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>-0.202651</td>\n",
       "      <td>-0.190083</td>\n",
       "      <td>0.119905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207299</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.171027</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.209799</td>\n",
       "      <td>-0.076251</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>-0.128018</td>\n",
       "      <td>-0.219210</td>\n",
       "      <td>0.101524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.393399</td>\n",
       "      <td>0.812363</td>\n",
       "      <td>1.035731</td>\n",
       "      <td>0.950012</td>\n",
       "      <td>1.032091</td>\n",
       "      <td>1.179388</td>\n",
       "      <td>0.882395</td>\n",
       "      <td>1.125494</td>\n",
       "      <td>1.749885</td>\n",
       "      <td>1.087180</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096488</td>\n",
       "      <td>1.200395</td>\n",
       "      <td>1.357701</td>\n",
       "      <td>1.052771</td>\n",
       "      <td>1.201918</td>\n",
       "      <td>1.115477</td>\n",
       "      <td>0.951264</td>\n",
       "      <td>1.230636</td>\n",
       "      <td>1.326193</td>\n",
       "      <td>1.417674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.513000</td>\n",
       "      <td>-5.737000</td>\n",
       "      <td>-9.104000</td>\n",
       "      <td>-5.998000</td>\n",
       "      <td>-6.369000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-8.337000</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.193000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-9.795000</td>\n",
       "      <td>-8.180000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-4.269000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.473075</td>\n",
       "      <td>-0.562200</td>\n",
       "      <td>-0.437750</td>\n",
       "      <td>-0.429575</td>\n",
       "      <td>-0.470925</td>\n",
       "      <td>-0.602225</td>\n",
       "      <td>-0.493900</td>\n",
       "      <td>-0.525175</td>\n",
       "      <td>-0.511675</td>\n",
       "      <td>-0.360200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433875</td>\n",
       "      <td>-0.502250</td>\n",
       "      <td>-0.537075</td>\n",
       "      <td>-0.508775</td>\n",
       "      <td>-0.606175</td>\n",
       "      <td>-0.506200</td>\n",
       "      <td>-0.353100</td>\n",
       "      <td>-0.544600</td>\n",
       "      <td>-0.554400</td>\n",
       "      <td>-0.523800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.008850</td>\n",
       "      <td>-0.046600</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.026900</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.017900</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.160450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>-0.005900</td>\n",
       "      <td>-0.013600</td>\n",
       "      <td>-0.027700</td>\n",
       "      <td>-0.011850</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>-0.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.403075</td>\n",
       "      <td>0.663925</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.465375</td>\n",
       "      <td>0.510425</td>\n",
       "      <td>0.528725</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.549225</td>\n",
       "      <td>0.697775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.492150</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.511175</td>\n",
       "      <td>0.409075</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.496400</td>\n",
       "      <td>0.536950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.039000</td>\n",
       "      <td>8.257000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.282000</td>\n",
       "      <td>7.333000</td>\n",
       "      <td>5.473000</td>\n",
       "      <td>8.887000</td>\n",
       "      <td>6.433000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.552000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.346000</td>\n",
       "      <td>5.444000</td>\n",
       "      <td>6.317000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.911000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                g-0           g-1           g-2           g-3           g-4  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean       0.248366     -0.095684      0.152253      0.081971      0.057347   \n",
       "std        1.393399      0.812363      1.035731      0.950012      1.032091   \n",
       "min       -5.513000     -5.737000     -9.104000     -5.998000     -6.369000   \n",
       "25%       -0.473075     -0.562200     -0.437750     -0.429575     -0.470925   \n",
       "50%       -0.008850     -0.046600      0.075200      0.008050     -0.026900   \n",
       "75%        0.525700      0.403075      0.663925      0.463400      0.465375   \n",
       "max       10.000000      5.039000      8.257000     10.000000     10.000000   \n",
       "\n",
       "                g-5           g-6           g-7           g-8           g-9  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      -0.138836      0.035961     -0.202651     -0.190083      0.119905   \n",
       "std        1.179388      0.882395      1.125494      1.749885      1.087180   \n",
       "min      -10.000000    -10.000000    -10.000000    -10.000000     -8.337000   \n",
       "25%       -0.602225     -0.493900     -0.525175     -0.511675     -0.360200   \n",
       "50%       -0.015650     -0.000650     -0.017900      0.010000      0.160450   \n",
       "75%        0.510425      0.528725      0.411900      0.549225      0.697775   \n",
       "max        7.282000      7.333000      5.473000      8.887000      6.433000   \n",
       "\n",
       "       ...         g-762         g-763         g-764         g-765  \\\n",
       "count  ...  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean   ...      0.207299      0.009161      0.171027      0.002316   \n",
       "std    ...      1.096488      1.200395      1.357701      1.052771   \n",
       "min    ...     -8.193000    -10.000000     -9.795000     -8.180000   \n",
       "25%    ...     -0.433875     -0.502250     -0.537075     -0.508775   \n",
       "50%    ...      0.059600     -0.005900     -0.013600     -0.027700   \n",
       "75%    ...      0.648500      0.492150      0.522500      0.457000   \n",
       "max    ...     10.000000      9.552000     10.000000      8.346000   \n",
       "\n",
       "              g-766         g-767         g-768         g-769         g-770  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      -0.209799     -0.076251      0.134162     -0.128018     -0.219210   \n",
       "std        1.201918      1.115477      0.951264      1.230636      1.326193   \n",
       "min      -10.000000    -10.000000     -4.269000    -10.000000    -10.000000   \n",
       "25%       -0.606175     -0.506200     -0.353100     -0.544600     -0.554400   \n",
       "50%       -0.011850      0.009900      0.005400      0.000600      0.028700   \n",
       "75%        0.483000      0.511175      0.409075      0.498500      0.496400   \n",
       "max        5.444000      6.317000     10.000000      5.911000     10.000000   \n",
       "\n",
       "              g-771  \n",
       "count  23814.000000  \n",
       "mean       0.101524  \n",
       "std        1.417674  \n",
       "min      -10.000000  \n",
       "25%       -0.523800  \n",
       "50%       -0.006500  \n",
       "75%        0.536950  \n",
       "max       10.000000  \n",
       "\n",
       "[8 rows x 772 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[GENES].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450285</td>\n",
       "      <td>-0.176778</td>\n",
       "      <td>-1.262943</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>-0.890670</td>\n",
       "      <td>0.393604</td>\n",
       "      <td>-0.703376</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.082941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>-0.4047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.429385</td>\n",
       "      <td>-0.226422</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>0.863835</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.669397</td>\n",
       "      <td>0.447651</td>\n",
       "      <td>1.207365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115802</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>-0.212644</td>\n",
       "      <td>-0.902482</td>\n",
       "      <td>-0.118799</td>\n",
       "      <td>-0.336548</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.572233</td>\n",
       "      <td>-0.261651</td>\n",
       "      <td>-0.638141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>-0.1321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590366</td>\n",
       "      <td>0.698760</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.147857</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>-1.433683</td>\n",
       "      <td>1.323147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.287454</td>\n",
       "      <td>-0.110246</td>\n",
       "      <td>-0.105291</td>\n",
       "      <td>-0.396913</td>\n",
       "      <td>0.090983</td>\n",
       "      <td>-0.211590</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>-0.326626</td>\n",
       "      <td>-0.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>24</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>-0.4726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492270</td>\n",
       "      <td>0.802396</td>\n",
       "      <td>0.332499</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>0.238577</td>\n",
       "      <td>-0.483204</td>\n",
       "      <td>0.585078</td>\n",
       "      <td>0.173586</td>\n",
       "      <td>-0.611718</td>\n",
       "      <td>1.607084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>24</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>-0.5565</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.364079</td>\n",
       "      <td>-0.375444</td>\n",
       "      <td>-1.433534</td>\n",
       "      <td>-0.858483</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>0.101450</td>\n",
       "      <td>0.435098</td>\n",
       "      <td>-0.219500</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>0.555680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>48</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>-0.2541</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511130</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>-0.166686</td>\n",
       "      <td>-0.458886</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>0.081750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>24</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.4299</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129357</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>0.302835</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>-1.737516</td>\n",
       "      <td>-0.531532</td>\n",
       "      <td>-0.351892</td>\n",
       "      <td>0.542268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>72</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>3.0790</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549881</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>1.124858</td>\n",
       "      <td>2.358549</td>\n",
       "      <td>4.598061</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.448931</td>\n",
       "      <td>3.509945</td>\n",
       "      <td>1.710206</td>\n",
       "      <td>-2.434251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time     g-0     g-1     g-2     g-3     g-4     g-5     g-6  \\\n",
       "0           24  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220   \n",
       "1           72  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341   \n",
       "2           48  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715   \n",
       "3           48 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590   \n",
       "4           72 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "23809       24  0.1394 -0.0636 -0.1112 -0.5080 -0.4713  0.7201  0.5773   \n",
       "23810       24 -1.3260  0.3478 -0.3743  0.9905 -0.7178  0.6621 -0.2252   \n",
       "23811       48  0.3942  0.3756  0.3109 -0.7389  0.5505 -0.0159 -0.2541   \n",
       "23812       24  0.6660  0.2324  0.4392  0.2044  0.8531 -0.0343  0.0323   \n",
       "23813       72 -0.8598  1.0240 -0.1361  0.7952 -0.3611 -3.6750 -1.2420   \n",
       "\n",
       "          g-7     g-8  ...   pca_C-5   pca_C-6   pca_C-7   pca_C-8   pca_C-9  \\\n",
       "0     -0.0326  0.5548  ... -0.450285 -0.176778 -1.262943  0.219107 -0.890670   \n",
       "1      0.3372 -0.4047  ...  0.063234  0.658824  0.429385 -0.226422  0.271831   \n",
       "2      0.2155  0.0065  ... -0.115802  0.726273 -0.212644 -0.902482 -0.118799   \n",
       "3      0.1792 -0.1321  ...  0.590366  0.698760  0.050321 -0.793301  0.295411   \n",
       "4     -0.1498 -0.8789  ... -0.000223 -0.287454 -0.110246 -0.105291 -0.396913   \n",
       "...       ...     ...  ...       ...       ...       ...       ...       ...   \n",
       "23809  0.3055 -0.4726  ... -0.492270  0.802396  0.332499 -0.204876  0.238577   \n",
       "23810 -0.5565  0.5112  ... -1.364079 -0.375444 -1.433534 -0.858483  1.072457   \n",
       "23811  0.1745 -0.0340  ... -0.511130 -0.035609 -0.310135 -0.166686 -0.458886   \n",
       "23812  0.0463  0.4299  ... -1.129357  0.020524 -0.043233 -0.440007  0.302835   \n",
       "23813  0.9146  3.0790  ...  3.549881  0.367554  1.124858  2.358549  4.598061   \n",
       "\n",
       "       pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0      0.393604 -0.703376 -0.615139  0.174407  0.082941  \n",
       "1      0.863835  0.003597  0.669397  0.447651  1.207365  \n",
       "2     -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n",
       "3      0.147857  0.056161  0.689218 -1.433683  1.323147  \n",
       "4      0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "23809 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n",
       "23810  0.101450  0.435098 -0.219500  0.377156  0.555680  \n",
       "23811 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n",
       "23812  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n",
       "23813  0.405195  0.448931  3.509945  1.710206 -2.434251  \n",
       "\n",
       "[23814 rows x 988 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-c9235cb5cf3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wombat/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'range'"
     ]
    }
   ],
   "source": [
    "train_features.range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3972</th>\n",
       "      <th>3973</th>\n",
       "      <th>3974</th>\n",
       "      <th>3975</th>\n",
       "      <th>3976</th>\n",
       "      <th>3977</th>\n",
       "      <th>3978</th>\n",
       "      <th>3979</th>\n",
       "      <th>3980</th>\n",
       "      <th>3981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c-0</th>\n",
       "      <td>-0.0600</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>-0.1312</td>\n",
       "      <td>-0.3998</td>\n",
       "      <td>-0.3774</td>\n",
       "      <td>0.0877</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>1.6360</td>\n",
       "      <td>-0.9646</td>\n",
       "      <td>-0.9629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>-0.2805</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>-0.2049</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>-0.1993</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.2594</td>\n",
       "      <td>-0.6305</td>\n",
       "      <td>-0.2457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-1</th>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>-1.4640</td>\n",
       "      <td>-4.5520</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>1.0270</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>1.1480</td>\n",
       "      <td>-0.0619</td>\n",
       "      <td>-1.1560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>-0.5374</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>-0.5181</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>-0.7662</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>-0.2459</td>\n",
       "      <td>-0.3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-2</th>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>-2.7350</td>\n",
       "      <td>-0.1659</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>-0.4382</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>-0.7304</td>\n",
       "      <td>-0.5949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>-0.5206</td>\n",
       "      <td>-0.8884</td>\n",
       "      <td>1.1720</td>\n",
       "      <td>-0.9564</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.3822</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-3</th>\n",
       "      <td>0.4043</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>-1.7790</td>\n",
       "      <td>-1.9630</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>0.7595</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.3754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>-0.1457</td>\n",
       "      <td>-1.3030</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>-0.3422</td>\n",
       "      <td>1.1630</td>\n",
       "      <td>0.4083</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-4</th>\n",
       "      <td>0.4213</td>\n",
       "      <td>0.3679</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>-2.8610</td>\n",
       "      <td>1.0060</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>-0.6229</td>\n",
       "      <td>-0.6140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.2672</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>-0.2577</td>\n",
       "      <td>1.1650</td>\n",
       "      <td>-0.4529</td>\n",
       "      <td>-0.0122</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.7936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-95</th>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>1.5880</td>\n",
       "      <td>1.4250</td>\n",
       "      <td>-1.3070</td>\n",
       "      <td>-1.1160</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2940</td>\n",
       "      <td>-0.3230</td>\n",
       "      <td>-0.4697</td>\n",
       "      <td>-0.1316</td>\n",
       "      <td>-0.0933</td>\n",
       "      <td>-0.4791</td>\n",
       "      <td>1.2730</td>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>-0.4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-96</th>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>1.2120</td>\n",
       "      <td>2.4670</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>-0.1167</td>\n",
       "      <td>-0.8745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7880</td>\n",
       "      <td>-0.0991</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>-0.0709</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>-0.2618</td>\n",
       "      <td>-0.4948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-97</th>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>-0.1241</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5257</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>-0.7379</td>\n",
       "      <td>-0.0608</td>\n",
       "      <td>-1.1280</td>\n",
       "      <td>-0.2790</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.0757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-98</th>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7848</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>-0.9622</td>\n",
       "      <td>-0.6420</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>-0.7511</td>\n",
       "      <td>-1.0710</td>\n",
       "      <td>-0.2062</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>-0.4167</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>-0.4205</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>-0.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-99</th>\n",
       "      <td>0.4176</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>-0.8154</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>1.3990</td>\n",
       "      <td>-0.3179</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>-0.2017</td>\n",
       "      <td>-0.4735</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>-0.6600</td>\n",
       "      <td>-0.0934</td>\n",
       "      <td>-0.1504</td>\n",
       "      <td>-0.0484</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 27796 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8     \\\n",
       "c-0  -0.0600  0.0927 -0.1312 -0.3998 -0.3774  0.0877  0.3467  1.6360 -0.9646   \n",
       "c-1   0.1083  0.2723 -1.4640 -4.5520  0.7364  1.0270  0.2555  1.1480 -0.0619   \n",
       "c-2   0.6864  0.2772  0.3394 -2.7350 -0.1659  0.4862 -0.4382  0.2302 -0.7304   \n",
       "c-3   0.4043  0.7776 -1.7790 -1.9630  0.2341  0.7869 -0.1401  0.7595  0.5345   \n",
       "c-4   0.4213  0.3679  0.2188 -2.8610  1.0060  0.7077  0.8019  0.2395 -0.6229   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "c-95  0.6584  0.4899 -0.3174 -1.2880 -0.3031  0.4519  1.5880  1.4250 -1.3070   \n",
       "c-96 -0.3981  0.1522 -0.6417 -1.6210  0.1094  1.2120  2.4670  0.6633 -0.1167   \n",
       "c-97  0.2139  0.1241 -0.2187 -0.8784  0.2885  0.3765  0.0357  0.4562 -0.1241   \n",
       "c-98  0.3801  0.6077 -1.4080 -0.3876 -0.3786  0.7848  0.1351 -0.9622 -0.6420   \n",
       "c-99  0.4176  0.7371  0.6931 -0.8154  0.7125  1.3990 -0.3179  0.0260  0.5543   \n",
       "\n",
       "        9     ...    3972    3973    3974    3975    3976    3977    3978  \\\n",
       "c-0  -0.9629  ...  0.1481 -0.2805  0.3196 -0.2049  0.4931 -0.1993  0.1407   \n",
       "c-1  -1.1560  ...  0.3085 -0.5374  0.2696 -0.5181  0.5948 -0.7662  0.5437   \n",
       "c-2  -0.5949  ...  0.6901  0.3796 -0.5206 -0.8884  1.1720 -0.9564  0.4300   \n",
       "c-3   0.3754  ...  0.1923  0.3994 -0.1457 -1.3030  0.2584 -0.3422  1.1630   \n",
       "c-4  -0.6140  ...  0.0397 -0.2672  0.4676 -0.2577  1.1650 -0.4529 -0.0122   \n",
       "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "c-95 -1.1160  ... -1.2940 -0.3230 -0.4697 -0.1316 -0.0933 -0.4791  1.2730   \n",
       "c-96 -0.8745  ...  1.7880 -0.0991  0.3694 -0.0709  0.3248 -1.2680  0.2614   \n",
       "c-97 -0.2716  ... -0.5257  0.4412  0.3465 -0.7379 -0.0608 -1.1280 -0.2790   \n",
       "c-98  0.0189  ...  0.6184 -0.7511 -1.0710 -0.2062  0.2712 -0.4167 -0.0131   \n",
       "c-99 -2.0000  ... -0.0088  0.3936 -0.2017 -0.4735  0.1293 -0.6600 -0.0934   \n",
       "\n",
       "        3979    3980    3981  \n",
       "c-0   0.2594 -0.6305 -0.2457  \n",
       "c-1   0.0530 -0.2459 -0.3490  \n",
       "c-2   0.3822  0.7818  0.2184  \n",
       "c-3   0.4083  0.3728  0.5001  \n",
       "c-4   0.9142  0.0080  0.7936  \n",
       "...      ...     ...     ...  \n",
       "c-95  0.4666  0.1286 -0.4041  \n",
       "c-96  0.0461 -0.2618 -0.4948  \n",
       "c-97  0.5888  0.5074  0.0757  \n",
       "c-98 -0.4205  0.7430 -0.1356  \n",
       "c-99 -0.1504 -0.0484  0.5280  \n",
       "\n",
       "[100 rows x 27796 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>967</th>\n",
       "      <th>968</th>\n",
       "      <th>969</th>\n",
       "      <th>970</th>\n",
       "      <th>971</th>\n",
       "      <th>972</th>\n",
       "      <th>973</th>\n",
       "      <th>974</th>\n",
       "      <th>975</th>\n",
       "      <th>976</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450285</td>\n",
       "      <td>-0.176778</td>\n",
       "      <td>-1.262943</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>-0.890670</td>\n",
       "      <td>0.393604</td>\n",
       "      <td>-0.703376</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.082941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.429385</td>\n",
       "      <td>-0.226422</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>0.863835</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.669397</td>\n",
       "      <td>0.447651</td>\n",
       "      <td>1.207365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115802</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>-0.212644</td>\n",
       "      <td>-0.902482</td>\n",
       "      <td>-0.118799</td>\n",
       "      <td>-0.336548</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.572233</td>\n",
       "      <td>-0.261651</td>\n",
       "      <td>-0.638141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590366</td>\n",
       "      <td>0.698760</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.147857</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>-1.433683</td>\n",
       "      <td>1.323147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.287454</td>\n",
       "      <td>-0.110246</td>\n",
       "      <td>-0.105291</td>\n",
       "      <td>-0.396913</td>\n",
       "      <td>0.090983</td>\n",
       "      <td>-0.211590</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>-0.326626</td>\n",
       "      <td>-0.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492270</td>\n",
       "      <td>0.802396</td>\n",
       "      <td>0.332499</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>0.238577</td>\n",
       "      <td>-0.483204</td>\n",
       "      <td>0.585078</td>\n",
       "      <td>0.173586</td>\n",
       "      <td>-0.611718</td>\n",
       "      <td>1.607084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.364079</td>\n",
       "      <td>-0.375444</td>\n",
       "      <td>-1.433534</td>\n",
       "      <td>-0.858483</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>0.101450</td>\n",
       "      <td>0.435098</td>\n",
       "      <td>-0.219500</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>0.555680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511130</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>-0.166686</td>\n",
       "      <td>-0.458886</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>0.081750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129357</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>0.302835</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>-1.737516</td>\n",
       "      <td>-0.531532</td>\n",
       "      <td>-0.351892</td>\n",
       "      <td>0.542268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549881</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>1.124858</td>\n",
       "      <td>2.358549</td>\n",
       "      <td>4.598061</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.448931</td>\n",
       "      <td>3.509945</td>\n",
       "      <td>1.710206</td>\n",
       "      <td>-2.434251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose       0       1       2  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...     ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "            3       4       5  ...       967       968       969       970  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ... -0.450285 -0.176778 -1.262943  0.219107   \n",
       "1      0.0604  1.0190  0.5207  ...  0.063234  0.658824  0.429385 -0.226422   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.115802  0.726273 -0.212644 -0.902482   \n",
       "3      0.5288  4.0620 -0.8095  ...  0.590366  0.698760  0.050321 -0.793301   \n",
       "4      0.6919  1.4180 -0.8244  ... -0.000223 -0.287454 -0.110246 -0.105291   \n",
       "...       ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ... -0.492270  0.802396  0.332499 -0.204876   \n",
       "23810  0.9905 -0.7178  0.6621  ... -1.364079 -0.375444 -1.433534 -0.858483   \n",
       "23811 -0.7389  0.5505 -0.0159  ... -0.511130 -0.035609 -0.310135 -0.166686   \n",
       "23812  0.2044  0.8531 -0.0343  ... -1.129357  0.020524 -0.043233 -0.440007   \n",
       "23813  0.7952 -0.3611 -3.6750  ...  3.549881  0.367554  1.124858  2.358549   \n",
       "\n",
       "            971       972       973       974       975       976  \n",
       "0     -0.890670  0.393604 -0.703376 -0.615139  0.174407  0.082941  \n",
       "1      0.271831  0.863835  0.003597  0.669397  0.447651  1.207365  \n",
       "2     -0.118799 -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n",
       "3      0.295411  0.147857  0.056161  0.689218 -1.433683  1.323147  \n",
       "4     -0.396913  0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "23809  0.238577 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n",
       "23810  1.072457  0.101450  0.435098 -0.219500  0.377156  0.555680  \n",
       "23811 -0.458886 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n",
       "23812  0.302835  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n",
       "23813  4.598061  0.405195  0.448931  3.509945  1.710206 -2.434251  \n",
       "\n",
       "[23814 rows x 981 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.5)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose       0       1       2       3       4  \\\n",
       "0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "            5       6  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0     -1.0120 -1.0220  ...                                      0   \n",
       "1      0.5207  0.2341  ...                                      0   \n",
       "2      1.2390  0.1715  ...                                      0   \n",
       "3     -0.8095 -1.9590  ...                                      0   \n",
       "4     -0.8244 -0.2800  ...                                      0   \n",
       "...       ...     ...  ...                                    ...   \n",
       "21943  0.4256 -0.1166  ...                                      0   \n",
       "21944  0.7201  0.5773  ...                                      0   \n",
       "21945  0.6621 -0.2252  ...                                      0   \n",
       "21946 -0.0343  0.0323  ...                                      0   \n",
       "21947 -3.6750 -1.2420  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "21943             0                0                  0   \n",
       "21944             0                0                  0   \n",
       "21945             0                0                  0   \n",
       "21946             0                0                  0   \n",
       "21947             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "21943                0          0                           0              0  \n",
       "21944                0          0                           0              0  \n",
       "21945                0          0                           0              0  \n",
       "21946                0          0                           0              0  \n",
       "21947                0          0                           0              0  \n",
       "\n",
       "[21948 rows x 1186 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning\n",
    "\n",
    "# for col in GENES:\n",
    "#     train.loc[:, f'{col}_bin'] = pd.cut(train[col], bins=3, labels=False)\n",
    "#     test.loc[:, f'{col}_bin'] = pd.cut(test[col], bins=3, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "\n",
    "# plt.figure(figsize=(16,16))\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# gene_choice = np.random.choice(len(GENES), 16)\n",
    "# for i, col in enumerate(gene_choice):\n",
    "#     plt.subplot(4, 4, i+1)\n",
    "#     plt.hist(train_features.loc[:, GENES[col]],bins=100, color='orange')\n",
    "#     plt.title(GENES[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ = train.copy() [Didn't wanted to actually normalize, so created a copy and normalized that for further calculation]\n",
    "# for col in GENES:\n",
    "    \n",
    "# #     train_[col] = (train[col]-np.mean(train[col])) / (np.std(train[col]))\n",
    "    \n",
    "#     mean = train_[col].mean()\n",
    "#     std = train_[col].std()\n",
    "\n",
    "#     std_r = mean + 4*std\n",
    "#     std_l = mean - 4*std\n",
    "\n",
    "#     drop = train_[col][(train_[col]>std_r) | (train_[col]<std_l)].index.values\n",
    "\n",
    "# train = train.drop(drop).reset_index(drop=True)\n",
    "# # folds = folds.drop(drop).reset_index(drop=True)\n",
    "# target = target.drop(drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_comp = 50\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train[CELLS]), pd.DataFrame(test[CELLS])])\n",
    "# data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "# train2 = data2[:train.shape[0]]; test2 = data2[train.shape[0]:]\n",
    "\n",
    "# train2 = pd.DataFrame(train2, columns=[f'c-{i}' for i in range(n_comp)])\n",
    "# test2 = pd.DataFrame(test2, columns=[f'c-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "# train = train.drop(columns=drop_cols)\n",
    "# test = test.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose       0       1       2       3       4  \\\n",
       "0      id_000644bb2      24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc      72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a      48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391      48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3      72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444      72      D1  0.1608 -1.0500  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed      24      D2  0.1394 -0.0636 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c      24      D2 -1.3260  0.3478 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c      24      D1  0.6660  0.2324  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b      72      D1 -0.8598  1.0240 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "            5       6  ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0     -1.0120 -1.0220  ...             0                0                  0   \n",
       "1      0.5207  0.2341  ...             0                0                  0   \n",
       "2      1.2390  0.1715  ...             0                0                  0   \n",
       "3     -0.8095 -1.9590  ...             0                0                  0   \n",
       "4     -0.8244 -0.2800  ...             0                0                  0   \n",
       "...       ...     ...  ...           ...              ...                ...   \n",
       "21943  0.4256 -0.1166  ...             0                0                  0   \n",
       "21944  0.7201  0.5773  ...             0                0                  0   \n",
       "21945  0.6621 -0.2252  ...             0                0                  0   \n",
       "21946 -0.0343  0.0323  ...             0                0                  0   \n",
       "21947 -3.6750 -1.2420  ...             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "21943                          0                                      0   \n",
       "21944                          0                                      0   \n",
       "21945                          0                                      0   \n",
       "21946                          0                                      0   \n",
       "21947                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                    0          0                           0              0   \n",
       "1                    0          0                           0              0   \n",
       "2                    0          0                           0              0   \n",
       "3                    0          0                           0              0   \n",
       "4                    0          0                           0              0   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943                0          0                           0              0   \n",
       "21944                0          0                           0              0   \n",
       "21945                0          0                           0              0   \n",
       "21946                0          0                           0              0   \n",
       "21947                0          0                           0              0   \n",
       "\n",
       "       kfold  \n",
       "0          0  \n",
       "1          2  \n",
       "2          1  \n",
       "3          2  \n",
       "4          2  \n",
       "...      ...  \n",
       "21943      0  \n",
       "21944      4  \n",
       "21945      0  \n",
       "21946      1  \n",
       "21947      2  \n",
       "\n",
       "[21948 rows x 1187 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1186)\n",
      "(21948, 1187)\n",
      "(3624, 980)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_C-5</th>\n",
       "      <th>pca_C-6</th>\n",
       "      <th>pca_C-7</th>\n",
       "      <th>pca_C-8</th>\n",
       "      <th>pca_C-9</th>\n",
       "      <th>pca_C-10</th>\n",
       "      <th>pca_C-11</th>\n",
       "      <th>pca_C-12</th>\n",
       "      <th>pca_C-13</th>\n",
       "      <th>pca_C-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450285</td>\n",
       "      <td>-0.176778</td>\n",
       "      <td>-1.262943</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>-0.890670</td>\n",
       "      <td>0.393604</td>\n",
       "      <td>-0.703376</td>\n",
       "      <td>-0.615139</td>\n",
       "      <td>0.174407</td>\n",
       "      <td>0.082941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.429385</td>\n",
       "      <td>-0.226422</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>0.863835</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.669397</td>\n",
       "      <td>0.447651</td>\n",
       "      <td>1.207365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115802</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>-0.212644</td>\n",
       "      <td>-0.902482</td>\n",
       "      <td>-0.118799</td>\n",
       "      <td>-0.336548</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.572233</td>\n",
       "      <td>-0.261651</td>\n",
       "      <td>-0.638141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590366</td>\n",
       "      <td>0.698760</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.147857</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>-1.433683</td>\n",
       "      <td>1.323147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.287454</td>\n",
       "      <td>-0.110246</td>\n",
       "      <td>-0.105291</td>\n",
       "      <td>-0.396913</td>\n",
       "      <td>0.090983</td>\n",
       "      <td>-0.211590</td>\n",
       "      <td>0.350304</td>\n",
       "      <td>-0.326626</td>\n",
       "      <td>-0.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492270</td>\n",
       "      <td>0.802396</td>\n",
       "      <td>0.332499</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>0.238577</td>\n",
       "      <td>-0.483204</td>\n",
       "      <td>0.585078</td>\n",
       "      <td>0.173586</td>\n",
       "      <td>-0.611718</td>\n",
       "      <td>1.607084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.364079</td>\n",
       "      <td>-0.375444</td>\n",
       "      <td>-1.433534</td>\n",
       "      <td>-0.858483</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>0.101450</td>\n",
       "      <td>0.435098</td>\n",
       "      <td>-0.219500</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>0.555680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511130</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>-0.166686</td>\n",
       "      <td>-0.458886</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>0.081750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129357</td>\n",
       "      <td>0.020524</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>0.302835</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>-1.737516</td>\n",
       "      <td>-0.531532</td>\n",
       "      <td>-0.351892</td>\n",
       "      <td>0.542268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.549881</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>1.124858</td>\n",
       "      <td>2.358549</td>\n",
       "      <td>4.598061</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.448931</td>\n",
       "      <td>3.509945</td>\n",
       "      <td>1.710206</td>\n",
       "      <td>-2.434251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...      ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...   pca_C-5   pca_C-6   pca_C-7   pca_C-8  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ... -0.450285 -0.176778 -1.262943  0.219107   \n",
       "1      0.0604  1.0190  0.5207  ...  0.063234  0.658824  0.429385 -0.226422   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.115802  0.726273 -0.212644 -0.902482   \n",
       "3      0.5288  4.0620 -0.8095  ...  0.590366  0.698760  0.050321 -0.793301   \n",
       "4      0.6919  1.4180 -0.8244  ... -0.000223 -0.287454 -0.110246 -0.105291   \n",
       "...       ...     ...     ...  ...       ...       ...       ...       ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ... -0.492270  0.802396  0.332499 -0.204876   \n",
       "23810  0.9905 -0.7178  0.6621  ... -1.364079 -0.375444 -1.433534 -0.858483   \n",
       "23811 -0.7389  0.5505 -0.0159  ... -0.511130 -0.035609 -0.310135 -0.166686   \n",
       "23812  0.2044  0.8531 -0.0343  ... -1.129357  0.020524 -0.043233 -0.440007   \n",
       "23813  0.7952 -0.3611 -3.6750  ...  3.549881  0.367554  1.124858  2.358549   \n",
       "\n",
       "        pca_C-9  pca_C-10  pca_C-11  pca_C-12  pca_C-13  pca_C-14  \n",
       "0     -0.890670  0.393604 -0.703376 -0.615139  0.174407  0.082941  \n",
       "1      0.271831  0.863835  0.003597  0.669397  0.447651  1.207365  \n",
       "2     -0.118799 -0.336548  0.015536  0.572233 -0.261651 -0.638141  \n",
       "3      0.295411  0.147857  0.056161  0.689218 -1.433683  1.323147  \n",
       "4     -0.396913  0.090983 -0.211590  0.350304 -0.326626 -0.344389  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "23809  0.238577 -0.483204  0.585078  0.173586 -0.611718  1.607084  \n",
       "23810  1.072457  0.101450  0.435098 -0.219500  0.377156  0.555680  \n",
       "23811 -0.458886 -0.003948  0.292592  0.331622 -0.006669  0.081750  \n",
       "23812  0.302835  0.776086 -1.737516 -0.531532 -0.351892  0.542268  \n",
       "23813  4.598061  0.405195  0.448931  3.509945  1.710206 -2.434251  \n",
       "\n",
       "[23814 rows x 991 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(4, 2)\n",
       "    (1): Embedding(17, 8)\n",
       "    (2): Embedding(17, 8)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.04, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(991, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1009, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=1024, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_szs = [(4,2), (17,8), (17,8)]\n",
    "#m = TabularModel(emb_szs, n_cont=2, out_sz=2, layers=[1000,500])\n",
    "\n",
    "m = TabularModel(emb_szs, n_cont=991, out_sz=200, layers=[1024,1024], ps=[0.3,0.3],\n",
    "                 emb_drop=0.04, y_range=None, use_bn=True, bn_final=False)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.245155855096883\n"
     ]
    }
   ],
   "source": [
    "#formula\n",
    "ns = train.shape[0]\n",
    "ni = target.shape[1]\n",
    "no = test.shape[1]\n",
    "\n",
    "alpha = 2\n",
    "\n",
    "\n",
    "nh = ns/(alpha * (ni + no))\n",
    "\n",
    "print(nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26052276"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#degrees of freedom\n",
    "ns * (ni+no)\n",
    "\n",
    "# For an automated procedure you'd start with an alpha of \n",
    "# 2 (twice as many degrees of freedom in your training data as your model) \n",
    "# and work your way up to 10 if the error (loss) for your training dataset is \n",
    "# significantly smaller than for your test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21948"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21948 / 1200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numhidden = 18.29\n",
    "alpha = 2\n",
    "def calcHiddenLayer(alpha=alpha, numHiddenLayers=18):\n",
    "\n",
    "    nio = ni+no\n",
    "    return [(ns//(alpha*(nio)))//numHiddenLayers]*numHiddenLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcHiddenLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I usually do whatever is found and then either do 2-3 of that size,\n",
    "# or I’ll half it each time (usually it) so layers=[NH, NH/2, NH/4] (sometimes the /4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns//(alpha*(ni+no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-2\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003a602efa0d43ba8e383ec9a9a84e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 0\n",
    "fold = 0 \n",
    "\n",
    "seed_everything(seed)\n",
    "\n",
    "train = process_data(folds)\n",
    "test_ = process_data(test)\n",
    "\n",
    "trn_idx = train[train['kfold'] != fold].index\n",
    "val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "\n",
    "class MoADataset_:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return (dct['x'], dct['y'])#dct\n",
    "\n",
    "train_dataset = MoADataset_(x_train, y_train)\n",
    "valid_dataset = MoADataset_(x_valid, y_valid)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = Model(\n",
    "    num_features=num_features,\n",
    "    num_targets=num_targets,\n",
    "    hidden_size=hidden_size,\n",
    ")\n",
    "\n",
    "#model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-7, weight_decay=WEIGHT_DECAY)\n",
    "# scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "#                                           max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(trainloader, end_lr=10, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=LEARNING_RATE, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.6012294646082581\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.07284837748323168\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.028350793689057446\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02100266505564962\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021490097437323868\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.019112395867705346\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.019468110169459513\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.018191179766186647\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.01867784150754628\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01795157425637756\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.01829815324584859\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01751391469900097\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01786791458995878\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.0175403876762305\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01780696579700579\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01735452650380986\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017615147893303547\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017215105811400074\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.01754359377251155\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017225105209009987\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017359053155920214\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01697687605129821\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01739121109004254\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017261270619928836\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01743623927451562\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01703740909163441\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017354400916214006\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017057532471205505\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017351942103140165\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01706742545855897\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.01732020842694286\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017092166654765605\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.017239561446173036\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016973802287663733\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017193638206716034\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01686178826327835\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017091558503823868\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016793077758380345\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016941851794557726\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016718012573463576\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016814721788725128\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016686421473111425\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016609391292044216\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016548024277601922\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01648853505300223\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016370728744992187\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016181088579089745\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016336711043758053\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016007944489356832\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016189692728221416\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015769864837436573\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016101444725479398\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015599939857434103\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016019528811531406\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015346881906515446\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01597991870450122\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015189653505449709\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01596181858330965\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015230195556321869\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.015964401619774953\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5992363001341405\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.07208530455827714\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028116195516633816\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.021258042114121575\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020510320808144585\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019039709812828473\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018970954569353573\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017880388508949963\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018083091562046953\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01748224970485483\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017759774467381445\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.0172530024977667\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017538228801087193\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017218027982328618\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01741880035378795\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017306556978396007\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01738831741006478\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01709873125489269\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017366760774799015\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01717836633324623\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017381995767894863\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017204493044742517\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017525672939592514\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01745572289718049\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017483285776730896\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01703327250267778\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017411073366099077\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016980034937816007\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017338953757037718\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017054415201502186\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01740272264873636\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017074937533055033\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017246161196110905\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.017124783779893602\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.017186116008762863\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01691575146147183\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.0170917976445154\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016871945054403373\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01697539731833166\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016805520494069373\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01681333689181053\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016669742949306964\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.016684520416015734\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01652428989431688\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016505720161333465\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016432385173227107\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01636144742909549\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016358279303780626\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016139103214431932\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016262243528451237\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.015861633402443884\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016190630782927786\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015639008670721367\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016109409289700644\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015464615731405607\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016105234622955322\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015297418493993473\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01605671269020864\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015214940080878096\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016083286942115853\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5964088457758012\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.06445431145174163\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.0278629072793368\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020191626729709762\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020240358346938225\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018778532690235546\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.019198588244077087\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017773930116423538\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.0181213297503258\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01766112345669951\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01780711598964273\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017469726902033602\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017567704384471628\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01723460044179644\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017435243528714214\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.0171976810587304\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01747630000708328\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017199147545865604\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017412164025818525\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01728820904557194\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017524587084957653\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017139084424291337\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01747060851936323\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017079089927886214\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01751014703641767\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017230923527053424\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017440352926327698\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017247202273990427\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017481134576803965\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01711650216685874\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017406572904977678\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01706030991460596\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017333380547284647\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01700333984834807\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017352153553856886\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016854759811290674\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01718683237803803\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016833440719970633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 19, train_loss: 0.01698481539885203\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01681796054222754\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016950430483489796\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01662271198417459\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01675029751588253\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01650572307407856\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016584014297341524\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01642881203442812\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016340858849656324\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016383345957313264\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016172836500935366\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016209292278758117\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015971242328700813\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016241162829101086\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01570350593090921\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01604797387761729\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015535689330241386\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01600923538208008\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015469107905105837\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.01597477187003408\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.01534066595596032\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015983563368873938\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5987317287295625\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0754691971199853\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.028341529958382034\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.0204904561064073\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020438266904565735\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018886897074324744\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.01890849332878555\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01809113978275231\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018141300201523995\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017542551005525247\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.01770311026442526\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01740581018051931\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017488830878088873\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017529937491885254\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01749511228442408\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017226936242410115\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01746213498889752\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01740392813725131\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017431242209251806\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017395073068993433\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01748154313047079\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017672585110579217\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017454348335825445\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017293773564909187\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017476723239203726\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017316436315221447\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.0174243806766859\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017305321991443634\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01743684995892471\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017240773966269832\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017276519315614216\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017149136933897222\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01724561154032531\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017185763668801105\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017191932955081913\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017099180950650147\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017093230059127443\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017027226303304943\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01698246673154442\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016968019971890107\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01688911451998612\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01686328404716083\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01667522037050862\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01669992349509682\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.0165392875711879\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016590275216315474\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016308268471418516\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016512974138770786\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016081781511235495\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016379340179264547\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.01588634250388629\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016291695487286362\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015642765092838934\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016223159352583543\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015411318731966658\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.01622290177536862\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015305515027780464\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016211072355508803\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.01527929735923375\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016199465495135103\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.598539868288714\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.07577643692493438\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.027306579269360805\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.0205225618822234\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.0203288271078381\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018684291892818044\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.018842997252131285\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01783870038177286\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018094225719139195\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.0175244110503367\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017730558297826327\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01729864121547767\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017543815278812595\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01715265049466065\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017505688748011988\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017202123627066614\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017452570204825504\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01723918853593724\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017456930096976568\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01714090249900307\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017505573608197163\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01737466084637812\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017502803557916828\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017093146086803505\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01755505453363277\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01720347332635096\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01749547908379548\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017180998304060526\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017471697134222242\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017034047123576913\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017447447120819404\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017101078719965048\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.0173081754423354\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016863217311246053\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.0173198396164546\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016950294641511782\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01716120067335989\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016830300992088657\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01713229779262042\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016775446411754404\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016917332163269537\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016664287288274085\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016771899792703167\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016482454485126904\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016583518091373255\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016423858968274935\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016383936864904303\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016289757112307207\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016123415936000536\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016202416909592492\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015947703778257837\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016079084921096054\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015751953149025423\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.0159884510827916\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015592469665073399\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015946520758526667\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015478575143261232\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015913301865969384\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015396035438322502\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01595832769359861\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6012732160372146\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.06861937663384847\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.0281508130736757\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02046175029660974\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.02025713106158419\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018666842526623182\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.019090429555786693\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017861932862017836\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018176409112208563\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017361558308558806\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.01765501995206527\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017087445062186037\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017460694961735735\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017084967105516366\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.01735950631858862\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017075081169605256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 8, train_loss: 0.017379898847877117\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017075920743601664\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017369987112402483\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017024151315646514\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017362960499535868\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01702987588942051\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01741488218523454\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017280552216938565\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017409678541825735\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01715456335140126\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017413402705088905\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017101124354771204\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017363987633607525\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016969448806984085\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017395802888263395\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016993500957531587\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.017320778355866238\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016881593210356576\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01717910268411472\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01683020136718239\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.0170549293777541\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016843150742352007\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016938087874618563\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016732344616736686\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016843712153048186\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016612455169005055\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016696526790442673\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016611892783216068\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016492636671856693\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01643327261720385\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01634798744234486\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016309869156352113\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.01614226669451033\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016207860995616233\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015821046405134424\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016132105035441262\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015602398157605658\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016059506844197\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015472867613847273\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.015976092751537052\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015300222713014355\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.015960213036409446\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015227647275542435\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.016007333914084095\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.5988949245192866\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.06613465643354825\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028096505116833294\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.020502337919814245\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02023084943547197\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018821474883173192\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.01887229454798111\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017756849128220762\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018042445796933294\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017374856264463494\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017748244484697563\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017237294864441668\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017543620173481926\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.01714516854179757\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017443263127158087\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017162013506250722\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01749855080160542\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017385611603302615\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017541445150593485\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017264800598578794\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017428391599568768\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017013259311871868\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017415608475119738\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017088791142616952\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017422537933495165\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017179126984306743\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017422026799370844\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017168062472982065\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017366783119792093\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.01703655333923442\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01732663513984585\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01704351156949997\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017343561914142058\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.017071299920124666\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.017255105840825083\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.0170610249042511\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017165145371109247\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016825536345796924\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01701146707046723\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016773441433906557\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01685959025812538\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016709107932235512\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.016715641889343227\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016584271831171855\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016536717350338247\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01643012213919844\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016293068051986073\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016412513170923505\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016123961664034403\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016300305458051816\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01589633712032135\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016182771804077286\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.0156640424663066\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016107054986059667\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015534538411251877\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.0160518669922437\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015312702563739773\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.016055317329508916\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015336384882043669\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016054402318383967\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6010321279366811\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.06996990420988627\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.028091331714413303\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02017931118607521\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02041054292973401\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018683391436934472\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.018891461591735697\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.018338291480072908\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018155525823164244\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.01748672356562955\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017784956215030474\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01712373276906354\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017558720104558313\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017356605960854463\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017439492998401755\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01718528547457286\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017455538532332233\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01708134010966335\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017356581655263468\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017164723681552068\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017480388553678127\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017027227713593416\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.01746105434427011\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017183697170444896\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017450697450102238\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01711487357637712\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017430929824763883\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01711000885282244\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017437155014308897\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01700992097279855\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.0173852674636072\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01702668076114995\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01738756255287191\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01691785901784897\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01728379405171111\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.01687960454395839\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.01713353645839337\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016824596960629736\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.017017619191682425\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01677443441003561\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016922197196686615\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01668964951698269\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016733431709471388\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016576492360660007\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016503446661205828\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01637097341673715\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.01643481036729139\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.0163079136716468\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016181134564829044\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01618522320474897\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015934574411021196\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.01608560433877366\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.015736331792035395\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.015971127897500992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 2, EPOCH: 27, train_loss: 0.01556611718420965\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.015939416284007687\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015393492914196373\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015897422097623348\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015322213904743177\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01593761518597603\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.600451173449772\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.07252676912716456\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.028246676238874596\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020924615061708857\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020389156726499397\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018805188685655595\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018870546981908272\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018002211089645115\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018071314772132082\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017725691944360734\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017779248800344656\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017375574606869903\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.01744932374930468\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017399039970976967\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017397948183065306\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017408431002071924\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017382295134112886\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01747751206691776\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01736794390540192\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01730383171566895\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01740455740144935\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01731805375644139\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017396667074628065\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01735958366521767\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017348266557614872\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017449748409645898\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017296448802116556\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017315606879336493\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017341563808799223\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01725028127964054\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017294937454541956\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017214310116001538\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017184304080201662\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017152233608067037\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017185295385349054\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017103226323212897\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01700052010246377\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01691511371838195\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016957751320054133\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01691705219979797\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016866805403074926\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01676941490066903\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016645198208752317\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01670567531670843\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01650620956459771\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01657820256160838\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.01627865884507048\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016464101736034666\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016063701084720484\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016419696967516627\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015850887026475823\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016343090975923198\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.01561929081040232\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016240922255175455\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015412704971875402\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016174006169395787\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015286393038442602\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016184646849121367\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015234519194379665\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016151531892163413\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.5994764874702778\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06904470835413251\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.027355948220128597\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020761415841323988\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020352820919799633\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01875762279544558\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01907956455766723\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.018092630590711322\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018039003669189802\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017379532594765934\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017714785769635786\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01714214232883283\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01748413873998367\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.01724898237735033\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017467145949764097\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017179802911622185\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017449263091860474\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.01719784140586853\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01748251737486841\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017028644042355674\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017400359471692987\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01728949070508991\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017549624410120472\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01713452719684158\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017480740424893473\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017116084322333337\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017463538033104894\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017085467145911287\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017433534754251225\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017037585510739257\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017386490519603958\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016917652689984866\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017306796389807394\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016996387259236405\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01724105859445273\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016813005746475287\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017173707890121834\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016840360233826297\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.017082671709088743\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016729314864746162\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016896768648555313\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016615964605339935\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016772580191331064\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01658421741532428\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016542053282044937\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01634738807167326\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016331566295222096\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016244788361447198\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01609461191717697\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016215323976108007\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015902737648212824\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016052573972514698\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.01566365013654897\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.016017498821020125\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015476259774110024\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015947571476655348\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015337879209360783\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01598180394087519\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.01524097155239703\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015944141335785388\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6010977184750895\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.08119981821094241\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027876649510817253\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020479563038264002\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020206880128092092\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018621617129870822\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.018827843007402145\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017814387248030732\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018230847164016704\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017462207483393805\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017602304050671883\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017369481229356356\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01744011853673104\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017076500691473484\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017377008569251368\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017127584692622932\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017401647612290537\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017153272085956166\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017384866178305685\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017088956385850906\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017430073291441237\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017226323245891503\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01748497571553225\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017345622394766128\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.01738437419028386\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01713571452668735\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01740440783644284\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01717126409390143\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017381421587281468\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016992720988179957\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017299349237557337\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016992693101721152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 16, train_loss: 0.017194650264159925\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01708337174994605\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017228408723367727\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01693269128778151\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017097427260022665\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016971422279519695\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.017105198897205402\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016693602608782904\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01686461998041773\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016577125393918583\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016758854143267523\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016634410353643554\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016548257604565308\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016422888184232372\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016347141187314108\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016343490460089274\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016087200965030468\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016206095181405544\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.01591007076068849\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016164592414030007\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.01573879428990725\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016067069795514855\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015472045033306315\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.016019852219947745\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01535888582441038\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.016001034235315664\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.01527749976494174\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.01601301548736436\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.599565643493248\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.0727195531129837\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.028668688286257828\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02115192147237914\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020521434590868328\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018875097536614965\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.01911421755220795\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.018085841674889837\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.01826488172662431\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.01744218229183129\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.01779179199450258\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017433205539626736\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017471292434071285\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017213507555425167\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.0174039495649977\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017108292851064886\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01740910434771491\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017140106776995317\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017269490860348593\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01696507478398936\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01727668102155777\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017286218463310174\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.01735722222972823\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01730334974293198\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017410678559563297\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01733213641813823\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017370958286135094\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017030542769602367\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017291322546214728\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016959119561527458\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017220122186278088\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017049552739730904\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017253348165178213\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016866971499153546\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01718383153522576\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016810562993798937\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01710257992364358\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01693591470164912\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.0169000715435739\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01680310807589974\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01678322867044936\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01661284494080714\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01664979579737005\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016507323192698615\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016462229819887358\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016436308356268064\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016218259066775226\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016308129419173513\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016054410926079836\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01624975712703807\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01577240807692642\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016158235046480382\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015588539389326521\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016115904785692692\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015379739648568026\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016046278976968358\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01520786801542061\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.016042473087353366\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015129329036057427\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.01601462710116591\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6020621034330216\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.07558992292199816\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.02798219149986255\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020685978553124835\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020321195594210556\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.019122256498251642\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.019082225319268047\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01806824617087841\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018152446607532707\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017748441733419894\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01770127945971014\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017467784588890416\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.0174862748902777\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017169859393366745\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017479260006676548\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017069294809230737\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017376628839343353\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017098239436745644\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017411281698909792\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01723080783018044\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.01742765752841597\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01721410099416971\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017459282118395186\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01723366720335824\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017393177840858698\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01712354969765459\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017454327725251947\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01713425692703043\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017414844277706266\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017112729538764273\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017344361778510654\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017218958719500473\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017345294113392414\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017111236469021865\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017290368588452322\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016886242638741222\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017202396472187145\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016720418924731868\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.017068058205093595\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016639430475022112\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01693797149978902\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016633550290550504\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016725433221005875\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01653136211846556\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016514060870352863\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016365826529051577\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016352319091126537\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016289566616926876\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016122580553148535\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016184468966509616\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.01591023237215004\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016059859097003935\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.015722914065733767\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01602118137691702\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.01553645927755945\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.015932781063020228\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015392343905093014\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.0159246542890157\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015324218394369751\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.01595704217574426\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.5999931710893693\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0661225329552378\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02762799467081609\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02060058233993394\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02031784487105366\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018886161648801397\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.019068251849840515\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018128135614097117\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018147658698422754\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017638245597481728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 5, train_loss: 0.017634178410567667\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01742887550166675\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017463133184482223\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017327695659228735\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017432376344188833\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017412867716380526\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01740516531213686\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01731897917176996\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01727837114257441\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017295954136976172\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017404154577440975\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01726268998214177\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01736542003472214\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0172422087884375\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017402951004982428\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017342890932091643\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017377105845219416\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017322623756315027\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017314591451777495\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017209384164639883\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017281494778243527\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01718647570482322\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017183629451724497\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017004470207861493\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01713300455847512\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017086738640708584\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017116509087761675\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017008709934140956\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.01692367851248254\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01694200967571565\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016825876880329157\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016716152802109717\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01659814022022529\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016836715542844365\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01645002533695188\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01663349217602185\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.01626489733926196\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016601324879697392\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016005960839760046\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016368358928178037\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015790316316744556\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016293005565447466\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015612597368063702\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01624059442962919\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.0153575769180189\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.01615486331284046\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015204557588836853\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016128461329000338\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015161492801068918\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016139563944722924\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6017425478692504\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06835596774305616\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.02780581233294114\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02029913727726255\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02054414271876432\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01869130688054221\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01895632459849551\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017833022587001323\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018171307401380676\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017527429520019462\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01780054961884583\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017387152276933195\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.01770339445953352\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017200012584882123\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017525347489593685\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017130360858781\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.01748973020500895\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017157684080302715\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017413069683032623\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017096218786069324\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017501015216112137\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01708664574793407\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017432944214754345\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017129929097635405\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01738353206546626\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01695688563798155\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017360346027366493\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01714660655707121\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017391346172308145\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01706492445830788\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017267677986967392\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017063563503324986\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01735036584643134\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01691035431410585\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.017209498258982447\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016828254663518498\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017169765223735485\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016785358265042304\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016945538111031055\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01668607017823628\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01691609555585445\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01653382685035467\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016660738338216925\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016443001957876343\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01648960297630317\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01633964202233723\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016336139939401462\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016283958591520785\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016059738475883354\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016095403395593167\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015813381627094055\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016044519282877444\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.01564554704785131\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01595798736172063\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015379601725093697\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01590239517390728\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015280439741099659\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015874859743884633\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.0152330936567075\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01586264515561717\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5984421269833178\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.07211000621318817\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027507967410096222\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.020249474634017262\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020140211745772674\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.018658101026500975\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.018874466878132545\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.01773005769188915\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018112711972840454\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01750054702694927\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017741664130564615\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017132022045552732\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.017470171209424734\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01714571818177189\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017468294763154743\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01719498998884644\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.017428803851531036\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017287167959979602\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017523889281395554\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017099258197205407\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017417505727675947\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.01715818750006812\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.017429253869298576\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017202931376440186\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017459978423742712\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017146201910717147\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01747604821930113\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017077383904584815\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017462640663311966\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017113511344151837\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017256623073278562\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017018165944942407\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01725522325495663\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.017062178200909068\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017140390844070826\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016899877999510083\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.01709382128024447\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016770427807101182\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016924186494957277\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016638757634375778\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01680453442900941\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016652426602584976\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016707431383268988\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016584969684481622\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.016462924640517736\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01644027259732996\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016366505799680086\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016355141385325362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 24, train_loss: 0.016090391554694244\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016187411599925587\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.01585920640280929\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016106772289744446\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015601785448582275\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.01602414660155773\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015489266092038673\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.015994311017649514\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.015342468071890913\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.01597602753234761\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015294621644568617\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.015967677852937154\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6012172058656595\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.07554061497960772\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02796580618166405\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.021167669658149993\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02052951556886884\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01923384756914207\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.01911231412457815\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01791261083313397\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018194777540106705\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017530998614217554\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.01780368005047026\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017239089070686272\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017407718762431457\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017315244621464183\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.017416794035259798\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017264804297259875\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.01733756364336696\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017129814385303428\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017376558011586683\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017126870421426636\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.017364223231224045\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01728205095444407\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017368362123227638\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01702114109482084\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01740076477922823\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017127819279474873\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017357404060337856\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016990094179553644\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017373756458307955\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017031013326985495\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017331571210229744\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01702562990997519\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017211843120015186\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01690138823219708\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01712246160225376\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016765812039375307\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.017026028157198343\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.01681239828467369\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.01693139264387065\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016769281136138098\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.016850355101506346\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016605548001825808\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01667630157527932\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016550541882004055\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016479076183252575\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01652537685419832\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016259788306079048\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016386162675917148\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016042891046221273\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016343555173703603\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.015755621648892975\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.01615793039756162\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015606246078791826\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016057656119976726\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015363152631544981\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016053746853555952\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.01521861974986783\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.01602578732584204\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015151315706147663\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016055430551724776\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.601312164541172\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.0792628390448434\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.028259268232985683\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.02183516483221735\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.0206989091416092\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01861293278634548\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.01894095986811579\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.01781232085611139\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018252125090878944\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017357737331518106\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.01770924745073569\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01727096542183842\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017496938149080328\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.01712980374161686\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017378302824184084\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017096791735717227\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017376140947791115\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017123669252863953\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017339347962937925\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017144776401775225\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017394432730540848\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01711823921650648\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017434617794672216\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.0172909341486437\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01738485841728423\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017135170607694556\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.01739987110098203\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017140434602541582\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.017321318064046944\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.01714709425078971\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017349836328809244\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017026869393885136\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.0173144164238719\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017029518048678124\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017285133921203837\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.017013478598424368\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017161940069248278\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016826993732580117\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.017037302370358637\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016742172597774437\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01686089562819056\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016633150327418533\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016711759961385658\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016609172044055803\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016626372238270182\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01640363120074783\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016397419709550297\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016245989501476286\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.01617280252115882\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01613337661006621\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015890565977526316\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016036770679056643\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01562191379270044\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.015995689321841512\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.01548683311979192\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.015919685683080127\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015367333095628714\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015925426914223603\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.015327510700655588\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015911709118102278\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6002879012106122\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0688460288303239\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.027918808216202087\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.021058282415781702\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.020541130133189152\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01882818772324494\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.018920440051326717\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.018012671412101815\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018103369390187057\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.01765920056828431\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017753536704981674\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017478215800864356\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017465573722037716\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017239853154335703\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.01740431803805025\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017318772471376826\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017395948775220608\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01726469038320439\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.01737028552705179\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017353478473212038\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017389874932342682\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017362714452402932\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017445455258037302\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017296119486646992\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.01741587141852664\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017355853665087906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 13, train_loss: 0.017397134686293808\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017174994439951012\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017378095591413803\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017217218929103443\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017450381853226303\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017217687224703175\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017381354903235384\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.017107104563287328\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01715434068624956\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01711808168994529\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01706275167753515\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01696129467870508\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016942480295572594\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016833088972738813\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016809823781089937\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016820520854422025\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.01666515882032505\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016695297669087138\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016503103502580652\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016593553258904388\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016380181569822024\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01647708426628794\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.01609207475827872\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016436169003801685\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015874661376996748\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.01627561237130846\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015656693082680737\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.0162557932681271\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015478955656020105\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.01622389094637973\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015365768588431503\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016161280231816427\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015286309394877459\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016168082265981605\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6008715411999087\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06718727094786507\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.028329161049771137\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02045348111007895\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020309171855341698\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018697293954236166\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01907819107282853\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01808583800281797\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.01817020294054047\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017385294501270566\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.01773875186462765\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017247274863932814\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017506195272764435\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017203658553106443\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.01744471062514661\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017174000665545464\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.01741100086466126\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017203271415616783\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01749309449983032\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017173513104873046\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.017499076681670504\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017101048970861094\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017476578324061375\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017095608689955303\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017448702185968126\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017017104050942828\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.01735360347463385\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01706781821059329\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017406373028305992\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017006791409637248\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.017331740886404896\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016900089462952954\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017277646728831787\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01690052119748933\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01727363258006348\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01687065325677395\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.017128039927532274\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01681091242602893\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.017010933301155117\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.0167365484471832\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.016828503695897\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016568460554948875\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01666825996927809\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016538578404911925\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016483373939990997\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016318412923387118\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01633341553742471\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01624150454465832\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016097551434422316\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016149366859878812\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015862835780379995\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016031178778835704\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015638993256657883\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.01596561899142606\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015478123957966116\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015914834210915225\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.015270562579288431\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015935638067977768\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015280896082412506\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.01590839121490717\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.6032406370816887\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.06258422029869896\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027786024616680283\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02076056259019034\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020683716402213642\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01878237027142729\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01888350962890663\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017738007807305882\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018202517438086048\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017488502578011583\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017827943966224575\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017157911456057003\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01747977576367017\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017103208228945732\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017353988272826307\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017148679388420924\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01734880150795199\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017072662924017226\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017377356303504843\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.0174979745809521\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017430397729132917\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017184224618332727\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01737986393002928\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017125594855419226\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.017362378881839308\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.016971382605178015\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.01741193987402147\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017059445168290818\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017338308357242226\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017031209410301278\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017309696791504604\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.01699448326336486\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.017235964860605156\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01693888170910733\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01715528143002935\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016839155847472805\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017074447921544746\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016781680738287313\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01692622329067925\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016676955989428928\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01680408800155788\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016633338827107633\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016752628488061222\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016543569655290673\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01651477606535174\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016384537384978363\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.01628955810641249\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01629612326089825\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016066517768616694\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.0161716721153685\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.01585398343783142\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.016062670493764537\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015668883346075167\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016022994661969797\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015418827898152496\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.01596136638628585\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01527811914169486\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.015990562603941987\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.015266769201211308\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.015954539605549403\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.6010509941564954\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.06839278638362885\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02747824554588052\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02065823668880122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 2, train_loss: 0.020294536768958187\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01859721466898918\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018939230914997017\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01771680215107543\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018102676209494257\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.018065163306891917\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017709309309451044\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017238434004996504\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.017461288936328197\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.0171205180564097\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01750698005375655\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01711597094046218\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017480130314125097\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017027201716388975\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017374562619227\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017180185791637215\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.01745529704308812\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017147103058440343\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017395530233456604\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01708003862627915\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.017464858398813267\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017284185705440384\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017430624688395124\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017112071439623833\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.01742098948823801\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017112082775150028\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.017328984097348177\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.017059307412377427\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017314869242355875\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01702777748661382\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.01725499869823672\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016963039019278116\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01710619541236024\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016853313094803264\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016962620429694653\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.01679087182773011\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01683522385639557\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.01666612114225115\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01665812655878456\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.016516384269509996\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016459369080384142\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01644226900701012\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016296246595194807\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01632513382605144\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01608071588249742\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016207979060709476\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.01582037617681899\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016153702405946595\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015594720212823671\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016097950057259627\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015453999949808138\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016039483887808664\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015300932596775068\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.016026770376733373\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015207426136602526\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016030147112905978\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.6009210619697536\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.07308546666588102\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.027885196986945644\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020058459149939672\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020223600681925167\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01874942577310971\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.01888049252844159\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017922600012804782\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.01813092173171648\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017424218356609344\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017741383566264656\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01722548521522965\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.017514372433441273\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017238891630300453\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017345974930440603\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.01707224811294249\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.017337856429588537\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017333878071180413\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.01742564295621022\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01724615144942488\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017485306395784668\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01707091283585344\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017470834419077288\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017051603724913936\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.01740904816466829\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017002464192254204\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017482752014167498\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017090445118291036\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.0174220963921128\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017054581961461476\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.017316443366470976\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016900918765791823\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.017303001513515694\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01693021665726389\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.017146137516027775\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016853909380733965\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017113772990263027\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016792692350489753\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.016966802506721106\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01658834003444229\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.016872484128976215\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016644165026290077\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.016704643685100735\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01645512812371765\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.016480155019224552\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016358946822583674\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016350243834481724\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016249396492327962\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.016131279234221016\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016103536236499037\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015918199944755306\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016037668713501523\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.015665646082303232\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.016028399605836186\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015463150929713594\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.01591246279754809\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015295688042660122\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015865044694926056\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.01526978869072121\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015912877688450473\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.599828778617624\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.0727668244923864\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02802818153809378\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.02044168093374797\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02046385797523502\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01886963966701712\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.019068938477531723\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017967431992292403\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.01808238244763967\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017559035069176127\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017619787074247564\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01730596763747079\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.017486203043465164\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017260871934039253\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017348895558034597\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01739497051707336\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.01731265542110887\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017308429894702774\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.017397672120157793\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.0174419636705092\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.017358439238876967\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.01720755539302315\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.01741770683936235\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0172473704708474\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017384553773571617\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017469526188714165\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.017340290096952864\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017301129469914096\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.017291912545814463\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.017280786990055017\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017301696636106655\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017078677458422526\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.017215540335662124\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01699226333626679\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.017132228935488325\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.017004234822733062\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.01704151711791106\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.017022853371288095\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.016915777239246643\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.0169112516567111\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01680109504799264\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01679880493985755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 21, train_loss: 0.016659555545049734\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.016735379158386163\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016518404923271442\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016599586472979613\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016269631515108587\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.016493061929941176\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.016031953823361277\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01635504394237484\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.01576060638425575\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016299985854753427\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015571494094109621\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.01624175464468343\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.01540298632386586\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016192706009106977\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.01528355128982145\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.016190630197525025\n",
      "FOLD: 3, EPOCH: 29, train_loss: 0.015174823630925106\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016177300177514554\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6015157858314721\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06817152862037931\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.028165952410494934\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.02024053202143737\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02018984242517879\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01886540060596807\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.01892026762842484\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01798180796738182\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018123981340423874\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.01742798060710941\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017734469434219427\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.01726801081427506\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017462387363817812\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017246097432715553\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017379458393037752\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017103303250457558\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.01745790304562104\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017116569727659226\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.01737214161919943\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017125831065433365\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01744733706953517\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017275047461901394\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017450589862098728\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017207061499357225\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.017460203797057056\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.016990309953689574\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017464384895519935\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017225941802774158\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.01746404932919836\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.017014150773840293\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.0173576303784722\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017068178047026906\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.01728907124935717\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.017006865409868104\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01722791544634147\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016980518427278313\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01709091452125838\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016768177705151693\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.016992819846432278\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016659757867455483\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01690489819030399\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016621532796749047\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016722008896370728\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016502268000372817\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.016494404322103313\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.01648840723293168\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016341352605841297\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016323212959936686\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.016171785307697195\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016222190244921615\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015874318657038006\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.01604753573025976\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.015668187175701925\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.015979627040880066\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015457422890956852\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.015933731544230667\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.01535196909411014\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.01588426668729101\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015237830889721712\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015901360527745316\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.5979891885341941\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.07056112736463546\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.027866713783663254\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.02036559320986271\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.020215811329367367\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01871643689061914\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.01888556940400082\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017797957280916828\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.018061778339408877\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017364702826099736\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.017649984506863184\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.01723807243896382\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.01745557580548136\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01716426903648036\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.017352979245555143\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017080271589968887\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.01738339784703609\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.016983739153615066\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.017530386025706928\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017106394576174872\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.017403745875302433\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.016984096222690172\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.01741058052773925\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01721342841961554\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.0174259251334529\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01713899134525231\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.017447221477556486\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01698493981467826\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.017387233019900927\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017149234057537148\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.017322650928374216\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.016911288989441737\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01722661061617343\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016949803116066114\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.017147868210314842\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01686536470162017\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.017075908721249172\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01669416254652398\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.016960592096860426\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016882328050477163\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.016844106048507536\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.01671053112617561\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.016706225016842716\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016558700720114367\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01649586916428761\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016433686230863845\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.016288229473529085\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016288377930011068\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.016098015739218048\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016225328775388854\n",
      "FOLD: 0, EPOCH: 25, train_loss: 0.015893821442580742\n",
      "FOLD: 0, EPOCH: 25, valid_loss: 0.01606847255357674\n",
      "FOLD: 0, EPOCH: 26, train_loss: 0.015643103675835806\n",
      "FOLD: 0, EPOCH: 26, valid_loss: 0.016035753994115762\n",
      "FOLD: 0, EPOCH: 27, train_loss: 0.015493317993114824\n",
      "FOLD: 0, EPOCH: 27, valid_loss: 0.016028522008231707\n",
      "FOLD: 0, EPOCH: 28, train_loss: 0.01533317499105697\n",
      "FOLD: 0, EPOCH: 28, valid_loss: 0.015993798284658363\n",
      "FOLD: 0, EPOCH: 29, train_loss: 0.01525017170343494\n",
      "FOLD: 0, EPOCH: 29, valid_loss: 0.015961561777762003\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.599717556728401\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.06876166611909866\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.02838097966235617\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.02035010281418051\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.020485829413477062\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.018935960531234742\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.018954387629755598\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01800836750439235\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.018126384928768526\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017429053437496934\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.017572981487635687\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017176973127893038\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.01739109554530486\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017335862959069866\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.01739970424576946\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.016966265147285803\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.017344087402781715\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017148075944611003\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.017226343306348375\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017219170076506477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1, EPOCH: 10, train_loss: 0.017337541082415028\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.016992962972394058\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.017346763733666445\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.01708397434226104\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.01742828887063956\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.017182683146425657\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.017452673959559288\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017218911168830734\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.017406015029258055\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.017019513196178844\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.0173011333209233\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01706404449152095\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.017219754752527544\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016915672751409667\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.017226119788930468\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.01690302129302706\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01712973928079009\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016692276698138032\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.016927063822800268\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016745563170739584\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.01675057386898476\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016677279344626834\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.01670243822551076\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.01662783766431468\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.016432640871599964\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.016495483448462828\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.016260854987616556\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.016336695716849394\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.016082619080670935\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.016237126636718002\n",
      "FOLD: 1, EPOCH: 25, train_loss: 0.015818398830521364\n",
      "FOLD: 1, EPOCH: 25, valid_loss: 0.016158373361187323\n",
      "FOLD: 1, EPOCH: 26, train_loss: 0.015532415974345327\n",
      "FOLD: 1, EPOCH: 26, valid_loss: 0.016148987678544863\n",
      "FOLD: 1, EPOCH: 27, train_loss: 0.015429512374912914\n",
      "FOLD: 1, EPOCH: 27, valid_loss: 0.016034235725445406\n",
      "FOLD: 1, EPOCH: 28, train_loss: 0.015298865816515425\n",
      "FOLD: 1, EPOCH: 28, valid_loss: 0.016074292893920625\n",
      "FOLD: 1, EPOCH: 29, train_loss: 0.015163870818535055\n",
      "FOLD: 1, EPOCH: 29, valid_loss: 0.016049947616245064\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.5998575085963028\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.06675444873315947\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.028036557583381302\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.020422685305987086\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.020466599262494972\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.01877719448613269\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.01894581325325197\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017979777843824454\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.018086669575153053\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017392993345856665\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.017671407726795776\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017302420788577626\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.0174523929093519\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017112410733742374\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.017524738276404314\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017240724286862782\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.01739520117289562\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017256544211081096\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.017415260018753834\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017087209943149773\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.017487808663829946\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017056771048477717\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.017470243440913982\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.01709542689578874\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.017545811710474285\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017094227724841662\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.017557716091581875\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017096234006541117\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.01744194553517129\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017139370074229582\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01738903589843624\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.016960956236081463\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01729806631371595\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016881806190524783\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01720339940536929\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016989073902368545\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.017188566203728533\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016878947695451122\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.017041173176435026\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016675943907882487\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.01692796589644707\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016609237316463674\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.0167241414833436\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016482718661427496\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01654379285764003\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01643754371574947\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.016303105293300705\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016270200988011702\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.01619572465078554\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01615630803363664\n",
      "FOLD: 2, EPOCH: 25, train_loss: 0.015918390845636957\n",
      "FOLD: 2, EPOCH: 25, valid_loss: 0.016101071823920524\n",
      "FOLD: 2, EPOCH: 26, train_loss: 0.01566569363374425\n",
      "FOLD: 2, EPOCH: 26, valid_loss: 0.01598650264952864\n",
      "FOLD: 2, EPOCH: 27, train_loss: 0.015533300778032213\n",
      "FOLD: 2, EPOCH: 27, valid_loss: 0.015931200475565024\n",
      "FOLD: 2, EPOCH: 28, train_loss: 0.015383559630076954\n",
      "FOLD: 2, EPOCH: 28, valid_loss: 0.015908386797777244\n",
      "FOLD: 2, EPOCH: 29, train_loss: 0.0152959319681901\n",
      "FOLD: 2, EPOCH: 29, valid_loss: 0.015913344706807817\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.6007138474479966\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.06443635608468737\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.02784626805425986\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.020534950654421534\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02040893404974022\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018820771681410924\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.0189619411147483\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017886949037866934\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.018153984248098255\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017520569397934845\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.017678733078249985\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.01732170887823616\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.01744920596399385\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.0172591486413564\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.017372522705599018\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017254282746996197\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.017364911492104115\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017284736649266313\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.0174011185468323\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017276137934199402\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.01744114497568512\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017286379768380097\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.017410421514532703\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.017324937001935072\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.017389275855722204\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.017440182502780642\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.0173996869555634\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017086609000606195\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.01738070001474757\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.01716807641621147\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.017262636454424996\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.017236942797899245\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01723242161012646\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.01700448031936373\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01711010957217735\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016956370776253088\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.017030135829649542\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01698038870734828\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.017002317919463352\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016985456618879523\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.016812268111422873\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016742780352277414\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.016666683604589838\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.01671783679297992\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.016530702653192522\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.016567212556089672\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.016358591474430716\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.0165352429662432\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.01606758863435707\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.016399519996983664\n",
      "FOLD: 3, EPOCH: 25, train_loss: 0.015779281743680654\n",
      "FOLD: 3, EPOCH: 25, valid_loss: 0.016303355353219168\n",
      "FOLD: 3, EPOCH: 26, train_loss: 0.015603119541175556\n",
      "FOLD: 3, EPOCH: 26, valid_loss: 0.016220612398215702\n",
      "FOLD: 3, EPOCH: 27, train_loss: 0.015405506239799053\n",
      "FOLD: 3, EPOCH: 27, valid_loss: 0.016171292827597685\n",
      "FOLD: 3, EPOCH: 28, train_loss: 0.015194921315634165\n",
      "FOLD: 3, EPOCH: 28, valid_loss: 0.01616262833454779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 3, EPOCH: 29, train_loss: 0.015131510490470606\n",
      "FOLD: 3, EPOCH: 29, valid_loss: 0.016157992157552925\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.6011913240063882\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.06963097878864834\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.027935690961886143\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.020257895652736935\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.020358053332977535\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018684232607483864\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.019055977969875803\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01796668576342719\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.018099716810536556\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017527896431939943\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.017683016628944788\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017223992331751755\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.017526558316920116\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017128692593957696\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.017433119613839233\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017125361120062216\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.017452500288145267\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.0174238918615239\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.017366818638275498\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017046454256134373\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.01751268221794263\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017102627296532905\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.017437798895643675\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.01723225571747337\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.01743736586439005\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017040809190699033\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.017506286231935887\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.0170337832399777\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.017467081162106733\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01707553741122995\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01734613488846715\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.01700031291693449\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.017326000166813963\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016852191223629884\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01724616305200734\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01686625387519598\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01715550671561041\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.01674163889672075\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.017019042920699154\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016683561514530862\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.01684627033419151\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016597445069679192\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.016731034329943897\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016511433465140207\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01651177288748432\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016391713385071074\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.016366175335386524\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01624844026352678\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01619415988713719\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016171834245324136\n",
      "FOLD: 4, EPOCH: 25, train_loss: 0.015927425815143448\n",
      "FOLD: 4, EPOCH: 25, valid_loss: 0.016018381768039294\n",
      "FOLD: 4, EPOCH: 26, train_loss: 0.01564308289654445\n",
      "FOLD: 4, EPOCH: 26, valid_loss: 0.016026957838663033\n",
      "FOLD: 4, EPOCH: 27, train_loss: 0.015474408223847116\n",
      "FOLD: 4, EPOCH: 27, valid_loss: 0.01592943250600781\n",
      "FOLD: 4, EPOCH: 28, train_loss: 0.01532355572461434\n",
      "FOLD: 4, EPOCH: 28, valid_loss: 0.015952643459396704\n",
      "FOLD: 4, EPOCH: 29, train_loss: 0.015284798998871574\n",
      "FOLD: 4, EPOCH: 29, valid_loss: 0.015920462938291687\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0, 1, 2, 3 ,4, 5]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014648880292108497\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
